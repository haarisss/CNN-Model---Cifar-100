<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>235b7d92b11d446d861ef40504ffe454</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      word-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell markdown" id="4708399f">
<p>Haaris Bin Sulaiman P2112815 CA1 Part B</p>
</div>
<section id="cifar-fine-mode" class="cell markdown" id="lUwTigLiTfTd">
<h1>CIFAR FINE MODE</h1>
</section>
<section id="data-preparation" class="cell markdown" id="R35B1xa0jRUZ">
<h2>DATA PREPARATION</h2>
</section>
<div class="cell code" id="f4b9142f">
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> mean</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> std</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> KFold</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.datasets <span class="im">import</span> fashion_mnist</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.utils <span class="im">import</span> to_categorical</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.models <span class="im">import</span> Sequential</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Conv2D</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> MaxPooling2D</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> BatchNormalization</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Dense</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Dropout</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Flatten</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.optimizers <span class="im">import</span> SGD</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="461e104e" data-outputId="a030c0fc-3b26-4552-d952-7d2df7828719">
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>(X_train, y_train), (X_test, y_test) <span class="op">=</span> tf.keras.datasets.cifar100.load_data(label_mode <span class="op">=</span> <span class="st">&#39;fine&#39;</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> X_train.shape <span class="op">==</span> (<span class="dv">50000</span>, <span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> X_test.shape <span class="op">==</span> (<span class="dv">10000</span>, <span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> y_train.shape <span class="op">==</span> (<span class="dv">50000</span>, <span class="dv">1</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> y_test.shape <span class="op">==</span> (<span class="dv">10000</span>, <span class="dv">1</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz
169001437/169001437 [==============================] - 2s 0us/step
</code></pre>
</div>
</div>
<section id="data-visualization" class="cell markdown" id="g2JBkogzmljv">
<h2>DATA VISUALIZATION</h2>
</section>
<div class="cell code" data-colab="{&quot;height&quot;:469,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="ec3bb2be" data-outputId="ba9bb608-f5c5-49bd-aa1d-b129d81c14a5">
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> visualize_random_images(images):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">8</span>))</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ind, img <span class="kw">in</span> <span class="bu">enumerate</span>(images[:<span class="dv">9</span>, :]):</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="bu">int</span>(<span class="st">&quot;33</span><span class="sc">%d</span><span class="st">&quot;</span> <span class="op">%</span> (ind <span class="op">+</span> <span class="dv">1</span>)))</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        plt.imshow(img)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        plt.xticks([])</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        plt.yticks([])</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>visualize_random_images(X_train)</span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/6fc65eccf4d42f47df2ca458a34549b22ec6db89.png" /></p>
</div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:604,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="9HzrBFnmlmUE" data-outputId="c146e0c7-a1d9-4734-fd04-99007ec8591e">
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">25</span>):</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    rand_num<span class="op">=</span>np.random.randint(<span class="dv">0</span>,<span class="dv">50000</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    cifar_img<span class="op">=</span>plt.subplot(<span class="dv">5</span>,<span class="dv">5</span>,i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    plt.imshow(X_train[rand_num])</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Erase the value of a tick</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    plt.xticks(color<span class="op">=</span><span class="st">&quot;None&quot;</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    plt.yticks(color<span class="op">=</span><span class="st">&quot;None&quot;</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Erase the tick x-axis and y-axis</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    plt.tick_params(length<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Show correct label</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    plt.title(y_train[rand_num])</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/3be874b52bbfd6db7599363191ddc46111b0e7bf.png" /></p>
</div>
</div>
<section id="data-preprocessing" class="cell markdown" id="f3Gn9m2tnAlN">
<h2>DATA PREPROCESSING</h2>
</section>
<div class="cell code" id="MgxFGWg-nDRv">
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># one hot encode target values</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co"># one hot encode target values</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> to_categorical(y_train,<span class="dv">100</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> to_categorical(y_test,<span class="dv">100</span>)</span></code></pre></div>
</div>
<div class="cell code" id="ulOFcugYnEw0">
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># scale pixels</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> prep_pixels(train, test):</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># convert from integers to floats</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    train_norm <span class="op">=</span> train.astype(<span class="st">&#39;float32&#39;</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    test_norm <span class="op">=</span> test.astype(<span class="st">&#39;float32&#39;</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># normalize to range 0-1</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    train_norm <span class="op">=</span> train_norm <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    test_norm <span class="op">=</span> test_norm <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return normalized images</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_norm, test_norm</span></code></pre></div>
</div>
<div class="cell code" id="T49F81gjnLZR">
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>X_train, X_test <span class="op">=</span> prep_pixels(X_train, X_test)</span></code></pre></div>
</div>
<section id="training-and-evaluaton" class="cell markdown" id="N80fJD2jmujS">
<h2>TRAINING AND EVALUATON</h2>
</section>
<div class="cell markdown">
<p>I will be making 3 baseline models, each getting more and more complexed. I will then be comaparing the training and test scores</p>
</div>
<section id="baseline-model-1" class="cell markdown" id="f813f230">
<h3>baseline model 1</h3>
</section>
<div class="cell code" id="db43e14HrcMw">
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)))</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>model.add(Flatten())</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>))</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>))</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co"># compile model</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;categorical_crossentropy&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="wCD9c0NrsAli" data-outputId="4b190de8-94b1-445a-89e6-2e0a5a2b7a15">
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>, batch_size<span class="op">=</span><span class="dv">32</span>, validation_data<span class="op">=</span>(X_test, y_test), verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 32, 32, 32)        896       
                                                                 
 conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      
                                                                 
 max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         
 )                                                               
                                                                 
 flatten (Flatten)           (None, 8192)              0         
                                                                 
 dense (Dense)               (None, 128)               1048704   
                                                                 
 dense_1 (Dense)             (None, 100)               12900     
                                                                 
=================================================================
Total params: 1,071,748
Trainable params: 1,071,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
1563/1563 [==============================] - 17s 5ms/step - loss: 3.6784 - accuracy: 0.1447 - val_loss: 3.1398 - val_accuracy: 0.2388
Epoch 2/10
1563/1563 [==============================] - 8s 5ms/step - loss: 2.8687 - accuracy: 0.2869 - val_loss: 2.8180 - val_accuracy: 0.2986
Epoch 3/10
1563/1563 [==============================] - 9s 5ms/step - loss: 2.4823 - accuracy: 0.3616 - val_loss: 2.6924 - val_accuracy: 0.3254
Epoch 4/10
1563/1563 [==============================] - 9s 6ms/step - loss: 2.2096 - accuracy: 0.4188 - val_loss: 2.6607 - val_accuracy: 0.3347
Epoch 5/10
1563/1563 [==============================] - 9s 6ms/step - loss: 1.9809 - accuracy: 0.4695 - val_loss: 2.7129 - val_accuracy: 0.3499
Epoch 6/10
1563/1563 [==============================] - 8s 5ms/step - loss: 1.7728 - accuracy: 0.5156 - val_loss: 2.7999 - val_accuracy: 0.3374
Epoch 7/10
1563/1563 [==============================] - 8s 5ms/step - loss: 1.5863 - accuracy: 0.5619 - val_loss: 2.9320 - val_accuracy: 0.3367
Epoch 8/10
1563/1563 [==============================] - 8s 5ms/step - loss: 1.4170 - accuracy: 0.6026 - val_loss: 3.1094 - val_accuracy: 0.3323
Epoch 9/10
1563/1563 [==============================] - 7s 5ms/step - loss: 1.2601 - accuracy: 0.6425 - val_loss: 3.4034 - val_accuracy: 0.3183
Epoch 10/10
1563/1563 [==============================] - 8s 5ms/step - loss: 1.1121 - accuracy: 0.6818 - val_loss: 3.6877 - val_accuracy: 0.3090
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/1e48663327d40b220bd4b56cea57c86f4d902c15.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Train accuracy of the model: 68.18000078201294
Train loss of the model:  1.112114667892456
Validation accuracy of the model:  0.3089999854564667
Validation loss of the model:  3.687716007232666
Test Loss: 3.687716007232666
Test Accuracy: 0.3089999854564667
</code></pre>
</div>
</div>
<section id="baseline-model-2" class="cell markdown" id="7878bf39">
<h3>baseline model 2</h3>
</section>
<div class="cell code" id="caa9ecd1">
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)))</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>model.add(Flatten())</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>))</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>))</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co"># compile model</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span> <span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;categorical_crossentropy&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="vronte5ezUvs" data-outputId="f49be1c9-5bbe-49cd-a559-34502bdfd1d9">
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>, batch_size<span class="op">=</span><span class="dv">32</span>, validation_data<span class="op">=</span>(X_test, y_test), verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential_1&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_2 (Conv2D)           (None, 32, 32, 32)        896       
                                                                 
 conv2d_3 (Conv2D)           (None, 32, 32, 32)        9248      
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 16, 16, 32)       0         
 2D)                                                             
                                                                 
 conv2d_4 (Conv2D)           (None, 16, 16, 64)        18496     
                                                                 
 conv2d_5 (Conv2D)           (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_2 (MaxPooling  (None, 8, 8, 64)         0         
 2D)                                                             
                                                                 
 flatten_1 (Flatten)         (None, 4096)              0         
                                                                 
 dense_2 (Dense)             (None, 128)               524416    
                                                                 
 dense_3 (Dense)             (None, 100)               12900     
                                                                 
=================================================================
Total params: 602,884
Trainable params: 602,884
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
1563/1563 [==============================] - 11s 6ms/step - loss: 3.6221 - accuracy: 0.1542 - val_loss: 3.0343 - val_accuracy: 0.2565
Epoch 2/10
1563/1563 [==============================] - 9s 6ms/step - loss: 2.7236 - accuracy: 0.3159 - val_loss: 2.5986 - val_accuracy: 0.3417
Epoch 3/10
1563/1563 [==============================] - 9s 6ms/step - loss: 2.2844 - accuracy: 0.4086 - val_loss: 2.4826 - val_accuracy: 0.3708
Epoch 4/10
1563/1563 [==============================] - 9s 6ms/step - loss: 1.9557 - accuracy: 0.4767 - val_loss: 2.4339 - val_accuracy: 0.3856
Epoch 5/10
1563/1563 [==============================] - 10s 7ms/step - loss: 1.6955 - accuracy: 0.5394 - val_loss: 2.4844 - val_accuracy: 0.3906
Epoch 6/10
1563/1563 [==============================] - 9s 6ms/step - loss: 1.4468 - accuracy: 0.5950 - val_loss: 2.6212 - val_accuracy: 0.3781
Epoch 7/10
1563/1563 [==============================] - 9s 6ms/step - loss: 1.2270 - accuracy: 0.6487 - val_loss: 2.9145 - val_accuracy: 0.3721
Epoch 8/10
1563/1563 [==============================] - 9s 6ms/step - loss: 1.0328 - accuracy: 0.6969 - val_loss: 3.1599 - val_accuracy: 0.3663
Epoch 9/10
1563/1563 [==============================] - 9s 6ms/step - loss: 0.8711 - accuracy: 0.7367 - val_loss: 3.4984 - val_accuracy: 0.3651
Epoch 10/10
1563/1563 [==============================] - 9s 6ms/step - loss: 0.7352 - accuracy: 0.7769 - val_loss: 3.7622 - val_accuracy: 0.3555
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/23d0c41ccff613aa1644de1a8503b547c2ef769e.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Train accuracy of the model: 77.68800258636475
Train loss of the model:  0.7351690530776978
Validation accuracy of the model:  0.3555000126361847
Validation loss of the model:  3.7622334957122803
Test Loss: 3.7622334957122803
Test Accuracy: 0.3555000126361847
</code></pre>
</div>
</div>
<section id="baseline-model-3" class="cell markdown" id="da2799b7">
<h3>baseline model 3</h3>
</section>
<div class="cell code" id="d535cee7">
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)))</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>model.add(Flatten())</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>))</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>))</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co"># compile model</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span> <span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;categorical_crossentropy&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="D3JUTFgKzsKr" data-outputId="d608e0d9-c9fa-452d-d7e0-432639824609">
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>, batch_size<span class="op">=</span><span class="dv">100</span>, validation_data<span class="op">=</span>(X_test, y_test), verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential_2&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_6 (Conv2D)           (None, 32, 32, 32)        896       
                                                                 
 conv2d_7 (Conv2D)           (None, 32, 32, 32)        9248      
                                                                 
 max_pooling2d_3 (MaxPooling  (None, 16, 16, 32)       0         
 2D)                                                             
                                                                 
 conv2d_8 (Conv2D)           (None, 16, 16, 64)        18496     
                                                                 
 conv2d_9 (Conv2D)           (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_4 (MaxPooling  (None, 8, 8, 64)         0         
 2D)                                                             
                                                                 
 conv2d_10 (Conv2D)          (None, 8, 8, 128)         73856     
                                                                 
 conv2d_11 (Conv2D)          (None, 8, 8, 128)         147584    
                                                                 
 max_pooling2d_5 (MaxPooling  (None, 4, 4, 128)        0         
 2D)                                                             
                                                                 
 flatten_2 (Flatten)         (None, 2048)              0         
                                                                 
 dense_4 (Dense)             (None, 128)               262272    
                                                                 
 dense_5 (Dense)             (None, 100)               12900     
                                                                 
=================================================================
Total params: 562,180
Trainable params: 562,180
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
500/500 [==============================] - 7s 12ms/step - loss: 3.8669 - accuracy: 0.1135 - val_loss: 3.3610 - val_accuracy: 0.1948
Epoch 2/10
500/500 [==============================] - 6s 11ms/step - loss: 3.0610 - accuracy: 0.2519 - val_loss: 2.8955 - val_accuracy: 0.2864
Epoch 3/10
500/500 [==============================] - 7s 14ms/step - loss: 2.6128 - accuracy: 0.3376 - val_loss: 2.5993 - val_accuracy: 0.3487
Epoch 4/10
500/500 [==============================] - 6s 12ms/step - loss: 2.2869 - accuracy: 0.4025 - val_loss: 2.4588 - val_accuracy: 0.3795
Epoch 5/10
500/500 [==============================] - 6s 13ms/step - loss: 2.0064 - accuracy: 0.4653 - val_loss: 2.3617 - val_accuracy: 0.3962
Epoch 6/10
500/500 [==============================] - 7s 15ms/step - loss: 1.7603 - accuracy: 0.5224 - val_loss: 2.3496 - val_accuracy: 0.4093
Epoch 7/10
500/500 [==============================] - 6s 13ms/step - loss: 1.5396 - accuracy: 0.5715 - val_loss: 2.4529 - val_accuracy: 0.4077
Epoch 8/10
500/500 [==============================] - 6s 13ms/step - loss: 1.3124 - accuracy: 0.6281 - val_loss: 2.5612 - val_accuracy: 0.4099
Epoch 9/10
500/500 [==============================] - 7s 15ms/step - loss: 1.1055 - accuracy: 0.6781 - val_loss: 2.6952 - val_accuracy: 0.4065
Epoch 10/10
500/500 [==============================] - 6s 12ms/step - loss: 0.9226 - accuracy: 0.7235 - val_loss: 2.9530 - val_accuracy: 0.3990
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/e3224ff0eb5d3548c927318053b933e78a7e0933.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Train accuracy of the model: 72.35400080680847
Train loss of the model:  0.9225706458091736
Validation accuracy of the model:  0.39899998903274536
Validation loss of the model:  2.9529590606689453
Test Loss: 2.95295786857605
Test Accuracy: 0.39899998903274536
</code></pre>
</div>
</div>
<div class="cell markdown" id="_mdsOZ2O5Ut6">
<p>The best baseline model is model 3 with the highest validation accuracy and test accuracy however this model is overfitted and thus we will now be making amendments:</p>
</div>
<section id="improving-the-model" class="cell markdown" id="bf6f172e">
<h1>IMPROVING THE MODEL</h1>
</section>
<section id="regularization" class="cell markdown" id="f2850ba3">
<h2>Regularization</h2>
</section>
<section id="dropout" class="cell markdown" id="qlZb10gf0v2W">
<h3>DROPOUT</h3>
</section>
<div class="cell code" id="845846bb">
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)))</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>model.add(Flatten())</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>))</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>))</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span> <span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;categorical_crossentropy&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="pz7DQXGMz59d" data-outputId="0ea6575e-004c-4ac2-91ba-07c8ea28cc15">
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>, batch_size<span class="op">=</span><span class="dv">32</span>, validation_data<span class="op">=</span>(X_test, y_test), verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential_3&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_12 (Conv2D)          (None, 32, 32, 32)        896       
                                                                 
 conv2d_13 (Conv2D)          (None, 32, 32, 32)        9248      
                                                                 
 max_pooling2d_6 (MaxPooling  (None, 16, 16, 32)       0         
 2D)                                                             
                                                                 
 dropout (Dropout)           (None, 16, 16, 32)        0         
                                                                 
 conv2d_14 (Conv2D)          (None, 16, 16, 64)        18496     
                                                                 
 conv2d_15 (Conv2D)          (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_7 (MaxPooling  (None, 8, 8, 64)         0         
 2D)                                                             
                                                                 
 dropout_1 (Dropout)         (None, 8, 8, 64)          0         
                                                                 
 conv2d_16 (Conv2D)          (None, 8, 8, 128)         73856     
                                                                 
 conv2d_17 (Conv2D)          (None, 8, 8, 128)         147584    
                                                                 
 max_pooling2d_8 (MaxPooling  (None, 4, 4, 128)        0         
 2D)                                                             
                                                                 
 dropout_2 (Dropout)         (None, 4, 4, 128)         0         
                                                                 
 flatten_3 (Flatten)         (None, 2048)              0         
                                                                 
 dense_6 (Dense)             (None, 128)               262272    
                                                                 
 dropout_3 (Dropout)         (None, 128)               0         
                                                                 
 dense_7 (Dense)             (None, 100)               12900     
                                                                 
=================================================================
Total params: 562,180
Trainable params: 562,180
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
1563/1563 [==============================] - 14s 8ms/step - loss: 4.0363 - accuracy: 0.0756 - val_loss: 3.6692 - val_accuracy: 0.1416
Epoch 2/10
1563/1563 [==============================] - 11s 7ms/step - loss: 3.4896 - accuracy: 0.1622 - val_loss: 3.1720 - val_accuracy: 0.2290
Epoch 3/10
1563/1563 [==============================] - 10s 7ms/step - loss: 3.1639 - accuracy: 0.2212 - val_loss: 2.8751 - val_accuracy: 0.2868
Epoch 4/10
1563/1563 [==============================] - 10s 6ms/step - loss: 2.9385 - accuracy: 0.2606 - val_loss: 2.7129 - val_accuracy: 0.3191
Epoch 5/10
1563/1563 [==============================] - 10s 6ms/step - loss: 2.7735 - accuracy: 0.2961 - val_loss: 2.5440 - val_accuracy: 0.3509
Epoch 6/10
1563/1563 [==============================] - 14s 9ms/step - loss: 2.6456 - accuracy: 0.3217 - val_loss: 2.4856 - val_accuracy: 0.3631
Epoch 7/10
1563/1563 [==============================] - 12s 7ms/step - loss: 2.5471 - accuracy: 0.3410 - val_loss: 2.3917 - val_accuracy: 0.3752
Epoch 8/10
1563/1563 [==============================] - 10s 6ms/step - loss: 2.4640 - accuracy: 0.3598 - val_loss: 2.3636 - val_accuracy: 0.3863
Epoch 9/10
1563/1563 [==============================] - 10s 6ms/step - loss: 2.3962 - accuracy: 0.3701 - val_loss: 2.3626 - val_accuracy: 0.3838
Epoch 10/10
1563/1563 [==============================] - 10s 6ms/step - loss: 2.3424 - accuracy: 0.3831 - val_loss: 2.3073 - val_accuracy: 0.3969
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/8281296d166f88eb025f1e53cb030d07a7e8f197.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Train accuracy of the model: 38.31000030040741
Train loss of the model:  2.3424484729766846
Validation accuracy of the model:  0.3968999981880188
Validation loss of the model:  2.307276964187622
Test Loss: 2.307276964187622
Test Accuracy: 0.3968999981880188
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>The validation accuracy with dropout does not really change as compared to the baseline model but lets try increasing the number of epoch since the model works well with increasinf epoch based on the graphs</p>
</div>
<div class="cell code" id="l2ndzrnx6_rI">
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fitting with 20 epoch</span></span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="Icm3Ma9M6_1D" data-outputId="f15a1a33-e589-4770-efbc-40be545b1a03" data-scrolled="false">
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">20</span>, batch_size<span class="op">=</span><span class="dv">32</span>, validation_data<span class="op">=</span>(X_test, y_test), verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential_5&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_18 (Conv2D)          (None, 32, 32, 32)        896       
                                                                 
 conv2d_19 (Conv2D)          (None, 32, 32, 32)        9248      
                                                                 
 max_pooling2d_9 (MaxPooling  (None, 16, 16, 32)       0         
 2D)                                                             
                                                                 
 dropout_4 (Dropout)         (None, 16, 16, 32)        0         
                                                                 
 conv2d_20 (Conv2D)          (None, 16, 16, 64)        18496     
                                                                 
 conv2d_21 (Conv2D)          (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_10 (MaxPoolin  (None, 8, 8, 64)         0         
 g2D)                                                            
                                                                 
 dropout_5 (Dropout)         (None, 8, 8, 64)          0         
                                                                 
 conv2d_22 (Conv2D)          (None, 8, 8, 128)         73856     
                                                                 
 conv2d_23 (Conv2D)          (None, 8, 8, 128)         147584    
                                                                 
 max_pooling2d_11 (MaxPoolin  (None, 4, 4, 128)        0         
 g2D)                                                            
                                                                 
 dropout_6 (Dropout)         (None, 4, 4, 128)         0         
                                                                 
 flatten_4 (Flatten)         (None, 2048)              0         
                                                                 
 dense_8 (Dense)             (None, 128)               262272    
                                                                 
 dropout_7 (Dropout)         (None, 128)               0         
                                                                 
 dense_9 (Dense)             (None, 100)               12900     
                                                                 
=================================================================
Total params: 562,180
Trainable params: 562,180
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
1563/1563 [==============================] - 13s 9ms/step - loss: 2.4478 - accuracy: 0.3609 - val_loss: 2.5131 - val_accuracy: 0.3638
Epoch 2/20
1563/1563 [==============================] - 11s 7ms/step - loss: 2.3938 - accuracy: 0.3727 - val_loss: 2.4733 - val_accuracy: 0.3652
Epoch 3/20
1563/1563 [==============================] - 13s 9ms/step - loss: 2.3533 - accuracy: 0.3824 - val_loss: 2.4479 - val_accuracy: 0.3750
Epoch 4/20
1563/1563 [==============================] - 12s 8ms/step - loss: 2.3117 - accuracy: 0.3901 - val_loss: 2.4343 - val_accuracy: 0.3796
Epoch 5/20
1563/1563 [==============================] - 17s 11ms/step - loss: 2.2719 - accuracy: 0.4001 - val_loss: 2.3884 - val_accuracy: 0.3895
Epoch 6/20
1563/1563 [==============================] - 10s 7ms/step - loss: 2.2514 - accuracy: 0.4045 - val_loss: 2.3909 - val_accuracy: 0.3884
Epoch 7/20
1563/1563 [==============================] - 10s 7ms/step - loss: 2.2114 - accuracy: 0.4146 - val_loss: 2.3635 - val_accuracy: 0.3926
Epoch 8/20
1563/1563 [==============================] - 11s 7ms/step - loss: 2.1832 - accuracy: 0.4188 - val_loss: 2.3328 - val_accuracy: 0.4010
Epoch 9/20
1563/1563 [==============================] - 11s 7ms/step - loss: 2.1613 - accuracy: 0.4230 - val_loss: 2.3333 - val_accuracy: 0.4031
Epoch 10/20
1563/1563 [==============================] - 11s 7ms/step - loss: 2.1361 - accuracy: 0.4286 - val_loss: 2.2755 - val_accuracy: 0.4136
Epoch 11/20
1563/1563 [==============================] - 11s 7ms/step - loss: 2.1095 - accuracy: 0.4329 - val_loss: 2.3346 - val_accuracy: 0.4002
Epoch 12/20
1563/1563 [==============================] - 11s 7ms/step - loss: 2.1013 - accuracy: 0.4352 - val_loss: 2.3228 - val_accuracy: 0.4069
Epoch 13/20
1563/1563 [==============================] - 11s 7ms/step - loss: 2.0721 - accuracy: 0.4403 - val_loss: 2.2924 - val_accuracy: 0.4158
Epoch 14/20
1563/1563 [==============================] - 11s 7ms/step - loss: 2.0590 - accuracy: 0.4484 - val_loss: 2.3402 - val_accuracy: 0.4052
Epoch 15/20
1563/1563 [==============================] - 11s 7ms/step - loss: 2.0366 - accuracy: 0.4500 - val_loss: 2.3004 - val_accuracy: 0.4216
Epoch 16/20
1563/1563 [==============================] - 11s 7ms/step - loss: 2.0202 - accuracy: 0.4528 - val_loss: 2.2790 - val_accuracy: 0.4187
Epoch 17/20
1563/1563 [==============================] - 10s 6ms/step - loss: 2.0024 - accuracy: 0.4575 - val_loss: 2.3262 - val_accuracy: 0.4138
Epoch 18/20
1563/1563 [==============================] - 11s 7ms/step - loss: 2.0014 - accuracy: 0.4586 - val_loss: 2.2863 - val_accuracy: 0.4143
Epoch 19/20
1563/1563 [==============================] - 10s 7ms/step - loss: 1.9836 - accuracy: 0.4606 - val_loss: 2.2429 - val_accuracy: 0.4226
Epoch 20/20
1563/1563 [==============================] - 13s 8ms/step - loss: 1.9752 - accuracy: 0.4643 - val_loss: 2.2480 - val_accuracy: 0.4250
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/33844b708100f82c73dccde8e9d58f26eea611d3.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Train accuracy of the model: 46.43000066280365
Train loss of the model:  1.9752439260482788
Validation accuracy of the model:  0.42500001192092896
Validation loss of the model:  2.2479846477508545
Test Loss: 2.2479846477508545
Test Accuracy: 0.42500001192092896
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>With increasing epoch, the test and train accuracy does get higher so lets continue to increase the number of epoch</p>
</div>
<div class="cell code" data-execution_count="1" id="1jAoJmr680IZ">
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fitting with 30 epochs</span></span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="3OQ-4ktQAelD" data-outputId="8ea1175b-61b7-47f2-a847-f216c529e3b9" data-scrolled="false">
<div class="sourceCode" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">30</span>, batch_size<span class="op">=</span><span class="dv">32</span>, validation_data<span class="op">=</span>(X_test, y_test), verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 32, 32, 32)        896       
                                                                 
 conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      
                                                                 
 max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         
 )                                                               
                                                                 
 dropout (Dropout)           (None, 16, 16, 32)        0         
                                                                 
 conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     
                                                                 
 conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         
 2D)                                                             
                                                                 
 dropout_1 (Dropout)         (None, 8, 8, 64)          0         
                                                                 
 conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     
                                                                 
 conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    
                                                                 
 max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         
 2D)                                                             
                                                                 
 dropout_2 (Dropout)         (None, 4, 4, 128)         0         
                                                                 
 flatten (Flatten)           (None, 2048)              0         
                                                                 
 dense (Dense)               (None, 128)               262272    
                                                                 
 dropout_3 (Dropout)         (None, 128)               0         
                                                                 
 dense_1 (Dense)             (None, 100)               12900     
                                                                 
=================================================================
Total params: 562,180
Trainable params: 562,180
Non-trainable params: 0
_________________________________________________________________
Epoch 1/30
1563/1563 [==============================] - 12s 6ms/step - loss: 4.1691 - accuracy: 0.0581 - val_loss: 3.7729 - val_accuracy: 0.1264
Epoch 2/30
1563/1563 [==============================] - 11s 7ms/step - loss: 3.6010 - accuracy: 0.1434 - val_loss: 3.2287 - val_accuracy: 0.2106
Epoch 3/30
1563/1563 [==============================] - 10s 6ms/step - loss: 3.3067 - accuracy: 0.1953 - val_loss: 3.0251 - val_accuracy: 0.2534
Epoch 4/30
1563/1563 [==============================] - 9s 6ms/step - loss: 3.1022 - accuracy: 0.2344 - val_loss: 2.8602 - val_accuracy: 0.2820
Epoch 5/30
1563/1563 [==============================] - 9s 6ms/step - loss: 2.9417 - accuracy: 0.2630 - val_loss: 2.7468 - val_accuracy: 0.3152
Epoch 6/30
1563/1563 [==============================] - 10s 6ms/step - loss: 2.8163 - accuracy: 0.2866 - val_loss: 2.6536 - val_accuracy: 0.3292
Epoch 7/30
1563/1563 [==============================] - 9s 6ms/step - loss: 2.7033 - accuracy: 0.3104 - val_loss: 2.5632 - val_accuracy: 0.3508
Epoch 8/30
1563/1563 [==============================] - 9s 6ms/step - loss: 2.6137 - accuracy: 0.3296 - val_loss: 2.5282 - val_accuracy: 0.3507
Epoch 9/30
1563/1563 [==============================] - 9s 6ms/step - loss: 2.5425 - accuracy: 0.3444 - val_loss: 2.4582 - val_accuracy: 0.3704
Epoch 10/30
1563/1563 [==============================] - 10s 6ms/step - loss: 2.4772 - accuracy: 0.3538 - val_loss: 2.4224 - val_accuracy: 0.3747
Epoch 11/30
1563/1563 [==============================] - 10s 6ms/step - loss: 2.4191 - accuracy: 0.3690 - val_loss: 2.3772 - val_accuracy: 0.3826
Epoch 12/30
1563/1563 [==============================] - 9s 6ms/step - loss: 2.3655 - accuracy: 0.3788 - val_loss: 2.4221 - val_accuracy: 0.3860
Epoch 13/30
1563/1563 [==============================] - 9s 6ms/step - loss: 2.3203 - accuracy: 0.3869 - val_loss: 2.3426 - val_accuracy: 0.3941
Epoch 14/30
1563/1563 [==============================] - 10s 6ms/step - loss: 2.2889 - accuracy: 0.3951 - val_loss: 2.3404 - val_accuracy: 0.3953
Epoch 15/30
1563/1563 [==============================] - 10s 6ms/step - loss: 2.2487 - accuracy: 0.4011 - val_loss: 2.3152 - val_accuracy: 0.3998
Epoch 16/30
1563/1563 [==============================] - 9s 6ms/step - loss: 2.2169 - accuracy: 0.4087 - val_loss: 2.2712 - val_accuracy: 0.4148
Epoch 17/30
1563/1563 [==============================] - 10s 6ms/step - loss: 2.1861 - accuracy: 0.4194 - val_loss: 2.2994 - val_accuracy: 0.4054
Epoch 18/30
1563/1563 [==============================] - 10s 6ms/step - loss: 2.1588 - accuracy: 0.4235 - val_loss: 2.2755 - val_accuracy: 0.4116
Epoch 19/30
1563/1563 [==============================] - 10s 6ms/step - loss: 2.1412 - accuracy: 0.4243 - val_loss: 2.2639 - val_accuracy: 0.4151
Epoch 20/30
1563/1563 [==============================] - 10s 6ms/step - loss: 2.1126 - accuracy: 0.4338 - val_loss: 2.2960 - val_accuracy: 0.4083
Epoch 21/30
1563/1563 [==============================] - 10s 6ms/step - loss: 2.0956 - accuracy: 0.4371 - val_loss: 2.3004 - val_accuracy: 0.4165
Epoch 22/30
1563/1563 [==============================] - 10s 6ms/step - loss: 2.0717 - accuracy: 0.4413 - val_loss: 2.2305 - val_accuracy: 0.4231
Epoch 23/30
1563/1563 [==============================] - 9s 6ms/step - loss: 2.0435 - accuracy: 0.4475 - val_loss: 2.2203 - val_accuracy: 0.4221
Epoch 24/30
1563/1563 [==============================] - 10s 6ms/step - loss: 2.0299 - accuracy: 0.4512 - val_loss: 2.2077 - val_accuracy: 0.4256
Epoch 25/30
1563/1563 [==============================] - 9s 6ms/step - loss: 1.9949 - accuracy: 0.4549 - val_loss: 2.2095 - val_accuracy: 0.4303
Epoch 26/30
1563/1563 [==============================] - 10s 6ms/step - loss: 1.9938 - accuracy: 0.4617 - val_loss: 2.2030 - val_accuracy: 0.4340
Epoch 27/30
1563/1563 [==============================] - 10s 6ms/step - loss: 1.9811 - accuracy: 0.4623 - val_loss: 2.3011 - val_accuracy: 0.4193
Epoch 28/30
1563/1563 [==============================] - 10s 6ms/step - loss: 1.9749 - accuracy: 0.4622 - val_loss: 2.2501 - val_accuracy: 0.4262
Epoch 29/30
1563/1563 [==============================] - 10s 6ms/step - loss: 1.9533 - accuracy: 0.4694 - val_loss: 2.2305 - val_accuracy: 0.4289
Epoch 30/30
1563/1563 [==============================] - 10s 6ms/step - loss: 1.9315 - accuracy: 0.4726 - val_loss: 2.2489 - val_accuracy: 0.4229
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/0790edcf31a1901a9f91979c5de7dbc806eb29c8.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Train accuracy of the model: 47.255998849868774
Train loss of the model:  1.9315215349197388
Validation accuracy of the model:  0.42289999127388
Validation loss of the model:  2.248945474624634
Test Loss: 2.248945474624634
Test Accuracy: 0.42289999127388
</code></pre>
</div>
</div>
<section id="data-augmentation--dropout" class="cell markdown" id="AdInGPn_10vJ">
<h3>DATA AUGMENTATION + DROPOUT</h3>
</section>
<div class="cell code" id="kFACxxLS15hu">
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)))</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>model.add(Flatten())</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>))</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>))</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span> <span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;categorical_crossentropy&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" id="J28dDGmC15kD">
<div class="sourceCode" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.preprocessing.image <span class="im">import</span> ImageDataGenerator</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>datagen <span class="op">=</span> ImageDataGenerator(</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>        featurewise_center<span class="op">=</span><span class="va">False</span>,  <span class="co"># set input mean to 0 over the dataset</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>        samplewise_center<span class="op">=</span><span class="va">False</span>,  <span class="co"># set each sample mean to 0</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>        featurewise_std_normalization<span class="op">=</span><span class="va">False</span>,  <span class="co"># divide inputs by std of the dataset</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>        samplewise_std_normalization<span class="op">=</span><span class="va">False</span>,  <span class="co"># divide each input by its std</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>        zca_whitening<span class="op">=</span><span class="va">False</span>,  <span class="co"># dimesion reduction</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>        rotation_range<span class="op">=</span><span class="fl">0.1</span>,  <span class="co"># randomly rotate images in the range</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>        zoom_range <span class="op">=</span> <span class="fl">0.1</span>, <span class="co"># Randomly zoom image</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>        width_shift_range<span class="op">=</span><span class="fl">0.1</span>,  <span class="co"># randomly shift images horizontally</span></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>        height_shift_range<span class="op">=</span><span class="fl">0.1</span>,  <span class="co"># randomly shift images vertically</span></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>        horizontal_flip<span class="op">=</span><span class="va">False</span>,  <span class="co"># randomly flip images</span></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>        vertical_flip<span class="op">=</span><span class="va">False</span>)  <span class="co"># randomly flip images</span></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>datagen.fit(X_train)</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="5kcoaQho2ANy" data-outputId="6dea91cd-0c0e-4f7b-92be-223c6faba7c5">
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit_generator(datagen.flow(X_train, y_train, batch_size<span class="op">=</span><span class="dv">32</span>),shuffle<span class="op">=</span><span class="va">True</span>, epochs<span class="op">=</span><span class="dv">10</span>, validation_data <span class="op">=</span> (X_test, y_test),</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>                              verbose <span class="op">=</span> <span class="dv">2</span>, steps_per_epoch<span class="op">=</span>X_train.shape[<span class="dv">0</span>] <span class="op">//</span> <span class="dv">100</span>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential_1&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_6 (Conv2D)           (None, 32, 32, 32)        896       
                                                                 
 conv2d_7 (Conv2D)           (None, 32, 32, 32)        9248      
                                                                 
 max_pooling2d_3 (MaxPooling  (None, 16, 16, 32)       0         
 2D)                                                             
                                                                 
 dropout_4 (Dropout)         (None, 16, 16, 32)        0         
                                                                 
 conv2d_8 (Conv2D)           (None, 16, 16, 64)        18496     
                                                                 
 conv2d_9 (Conv2D)           (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_4 (MaxPooling  (None, 8, 8, 64)         0         
 2D)                                                             
                                                                 
 dropout_5 (Dropout)         (None, 8, 8, 64)          0         
                                                                 
 conv2d_10 (Conv2D)          (None, 8, 8, 128)         73856     
                                                                 
 conv2d_11 (Conv2D)          (None, 8, 8, 128)         147584    
                                                                 
 max_pooling2d_5 (MaxPooling  (None, 4, 4, 128)        0         
 2D)                                                             
                                                                 
 dropout_6 (Dropout)         (None, 4, 4, 128)         0         
                                                                 
 flatten_1 (Flatten)         (None, 2048)              0         
                                                                 
 dense_2 (Dense)             (None, 128)               262272    
                                                                 
 dropout_7 (Dropout)         (None, 128)               0         
                                                                 
 dense_3 (Dense)             (None, 100)               12900     
                                                                 
=================================================================
Total params: 562,180
Trainable params: 562,180
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
500/500 - 11s - loss: 4.4698 - accuracy: 0.0223 - val_loss: 4.2916 - val_accuracy: 0.0618 - 11s/epoch - 22ms/step
Epoch 2/10
500/500 - 9s - loss: 4.1390 - accuracy: 0.0606 - val_loss: 4.0216 - val_accuracy: 0.0852 - 9s/epoch - 19ms/step
Epoch 3/10
500/500 - 10s - loss: 3.9350 - accuracy: 0.0894 - val_loss: 3.8162 - val_accuracy: 0.1172 - 10s/epoch - 19ms/step
Epoch 4/10
500/500 - 10s - loss: 3.7941 - accuracy: 0.1099 - val_loss: 3.5954 - val_accuracy: 0.1417 - 10s/epoch - 20ms/step
Epoch 5/10
500/500 - 10s - loss: 3.6708 - accuracy: 0.1250 - val_loss: 3.6633 - val_accuracy: 0.1453 - 10s/epoch - 20ms/step
Epoch 6/10
500/500 - 10s - loss: 3.5748 - accuracy: 0.1417 - val_loss: 3.3821 - val_accuracy: 0.1953 - 10s/epoch - 20ms/step
Epoch 7/10
500/500 - 10s - loss: 3.4754 - accuracy: 0.1618 - val_loss: 3.3189 - val_accuracy: 0.1955 - 10s/epoch - 21ms/step
Epoch 8/10
500/500 - 10s - loss: 3.3937 - accuracy: 0.1789 - val_loss: 3.2483 - val_accuracy: 0.2093 - 10s/epoch - 20ms/step
Epoch 9/10
500/500 - 10s - loss: 3.3439 - accuracy: 0.1856 - val_loss: 3.1700 - val_accuracy: 0.2314 - 10s/epoch - 19ms/step
Epoch 10/10
500/500 - 10s - loss: 3.2836 - accuracy: 0.2007 - val_loss: 3.1255 - val_accuracy: 0.2395 - 10s/epoch - 19ms/step
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/8c708304d4c28d3c10a23556a4993708953f64e4.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Train accuracy of the model: 20.070070028305054
Train loss of the model:  3.283585548400879
Validation accuracy of the model:  0.2395000010728836
Validation loss of the model:  3.1255364418029785
Test Loss: 3.1255364418029785
Test Accuracy: 0.2395000010728836
</code></pre>
</div>
</div>
<div class="cell markdown" id="Wn-32JWdDVaa">
<p>Test accuracy and validation accuracy with data augmentation is much lower and thus we will not be using it and there is no need to test out with a larger epoch</p>
</div>
<section id="best-model---baseline-model-3--dropout" class="cell markdown" id="AqVe5pDc70Yl">
<h2>BEST MODEL - Baseline Model 3 + Dropout</h2>
</section>
<div class="cell code" id="HOnO8fMG723f">
<div class="sourceCode" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)))</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>model.add(Flatten())</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>))</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>))</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span> <span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;categorical_crossentropy&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="GQ36I7uf7250" data-outputId="462589c2-bce8-4155-ce8a-97b416243769">
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">50</span>, batch_size<span class="op">=</span><span class="dv">32</span>, validation_data<span class="op">=</span>(X_test, y_test), verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential_2&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_12 (Conv2D)          (None, 32, 32, 32)        896       
                                                                 
 conv2d_13 (Conv2D)          (None, 32, 32, 32)        9248      
                                                                 
 max_pooling2d_6 (MaxPooling  (None, 16, 16, 32)       0         
 2D)                                                             
                                                                 
 dropout_8 (Dropout)         (None, 16, 16, 32)        0         
                                                                 
 conv2d_14 (Conv2D)          (None, 16, 16, 64)        18496     
                                                                 
 conv2d_15 (Conv2D)          (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_7 (MaxPooling  (None, 8, 8, 64)         0         
 2D)                                                             
                                                                 
 dropout_9 (Dropout)         (None, 8, 8, 64)          0         
                                                                 
 conv2d_16 (Conv2D)          (None, 8, 8, 128)         73856     
                                                                 
 conv2d_17 (Conv2D)          (None, 8, 8, 128)         147584    
                                                                 
 max_pooling2d_8 (MaxPooling  (None, 4, 4, 128)        0         
 2D)                                                             
                                                                 
 dropout_10 (Dropout)        (None, 4, 4, 128)         0         
                                                                 
 flatten_2 (Flatten)         (None, 2048)              0         
                                                                 
 dense_4 (Dense)             (None, 128)               262272    
                                                                 
 dropout_11 (Dropout)        (None, 128)               0         
                                                                 
 dense_5 (Dense)             (None, 100)               12900     
                                                                 
=================================================================
Total params: 562,180
Trainable params: 562,180
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50
1563/1563 [==============================] - 11s 6ms/step - loss: 4.1487 - accuracy: 0.0624 - val_loss: 3.6783 - val_accuracy: 0.1369
Epoch 2/50
1563/1563 [==============================] - 10s 6ms/step - loss: 3.5083 - accuracy: 0.1577 - val_loss: 3.2056 - val_accuracy: 0.2249
Epoch 3/50
1563/1563 [==============================] - 10s 6ms/step - loss: 3.1758 - accuracy: 0.2180 - val_loss: 3.0255 - val_accuracy: 0.2520
Epoch 4/50
1563/1563 [==============================] - 11s 7ms/step - loss: 2.9589 - accuracy: 0.2604 - val_loss: 2.7483 - val_accuracy: 0.3076
Epoch 5/50
1563/1563 [==============================] - 10s 6ms/step - loss: 2.7928 - accuracy: 0.2925 - val_loss: 2.6623 - val_accuracy: 0.3223
Epoch 6/50
1563/1563 [==============================] - 10s 7ms/step - loss: 2.6607 - accuracy: 0.3172 - val_loss: 2.5115 - val_accuracy: 0.3539
Epoch 7/50
1563/1563 [==============================] - 10s 6ms/step - loss: 2.5573 - accuracy: 0.3348 - val_loss: 2.4541 - val_accuracy: 0.3661
Epoch 8/50
1563/1563 [==============================] - 10s 6ms/step - loss: 2.4793 - accuracy: 0.3550 - val_loss: 2.4649 - val_accuracy: 0.3669
Epoch 9/50
1563/1563 [==============================] - 11s 7ms/step - loss: 2.4078 - accuracy: 0.3669 - val_loss: 2.4009 - val_accuracy: 0.3806
Epoch 10/50
1563/1563 [==============================] - 10s 7ms/step - loss: 2.3506 - accuracy: 0.3800 - val_loss: 2.3266 - val_accuracy: 0.3930
Epoch 11/50
1563/1563 [==============================] - 10s 6ms/step - loss: 2.2915 - accuracy: 0.3937 - val_loss: 2.2919 - val_accuracy: 0.4007
Epoch 12/50
1563/1563 [==============================] - 10s 6ms/step - loss: 2.2502 - accuracy: 0.4038 - val_loss: 2.2545 - val_accuracy: 0.4116
Epoch 13/50
1563/1563 [==============================] - 10s 6ms/step - loss: 2.2149 - accuracy: 0.4096 - val_loss: 2.2122 - val_accuracy: 0.4183
Epoch 14/50
1563/1563 [==============================] - 10s 6ms/step - loss: 2.1732 - accuracy: 0.4190 - val_loss: 2.2598 - val_accuracy: 0.4129
Epoch 15/50
1563/1563 [==============================] - 10s 6ms/step - loss: 2.1410 - accuracy: 0.4254 - val_loss: 2.1966 - val_accuracy: 0.4186
Epoch 16/50
1563/1563 [==============================] - 10s 6ms/step - loss: 2.1036 - accuracy: 0.4338 - val_loss: 2.2328 - val_accuracy: 0.4250
Epoch 17/50
1563/1563 [==============================] - 10s 6ms/step - loss: 2.0705 - accuracy: 0.4417 - val_loss: 2.1982 - val_accuracy: 0.4253
Epoch 18/50
1563/1563 [==============================] - 10s 6ms/step - loss: 2.0443 - accuracy: 0.4474 - val_loss: 2.1785 - val_accuracy: 0.4339
Epoch 19/50
1563/1563 [==============================] - 10s 6ms/step - loss: 2.0305 - accuracy: 0.4501 - val_loss: 2.2110 - val_accuracy: 0.4259
Epoch 20/50
1563/1563 [==============================] - 9s 6ms/step - loss: 1.9968 - accuracy: 0.4585 - val_loss: 2.2166 - val_accuracy: 0.4346
Epoch 21/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.9927 - accuracy: 0.4563 - val_loss: 2.1979 - val_accuracy: 0.4299
Epoch 22/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.9712 - accuracy: 0.4649 - val_loss: 2.1979 - val_accuracy: 0.4351
Epoch 23/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.9528 - accuracy: 0.4677 - val_loss: 2.2119 - val_accuracy: 0.4361
Epoch 24/50
1563/1563 [==============================] - 10s 7ms/step - loss: 1.9328 - accuracy: 0.4735 - val_loss: 2.1449 - val_accuracy: 0.4440
Epoch 25/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.9073 - accuracy: 0.4799 - val_loss: 2.2210 - val_accuracy: 0.4270
Epoch 26/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.9048 - accuracy: 0.4807 - val_loss: 2.2144 - val_accuracy: 0.4309
Epoch 27/50
1563/1563 [==============================] - 9s 6ms/step - loss: 1.8878 - accuracy: 0.4827 - val_loss: 2.1702 - val_accuracy: 0.4373
Epoch 28/50
1563/1563 [==============================] - 9s 6ms/step - loss: 1.8679 - accuracy: 0.4869 - val_loss: 2.1486 - val_accuracy: 0.4452
Epoch 29/50
1563/1563 [==============================] - 9s 6ms/step - loss: 1.8641 - accuracy: 0.4863 - val_loss: 2.1714 - val_accuracy: 0.4411
Epoch 30/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.8503 - accuracy: 0.4918 - val_loss: 2.1741 - val_accuracy: 0.4466
Epoch 31/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.8357 - accuracy: 0.4938 - val_loss: 2.1588 - val_accuracy: 0.4492
Epoch 32/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.8103 - accuracy: 0.5000 - val_loss: 2.1745 - val_accuracy: 0.4473
Epoch 33/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.8195 - accuracy: 0.4984 - val_loss: 2.1734 - val_accuracy: 0.4482
Epoch 34/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.8062 - accuracy: 0.5025 - val_loss: 2.1738 - val_accuracy: 0.4483
Epoch 35/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.7991 - accuracy: 0.5047 - val_loss: 2.1986 - val_accuracy: 0.4381
Epoch 36/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.7887 - accuracy: 0.5047 - val_loss: 2.1848 - val_accuracy: 0.4498
Epoch 37/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.7825 - accuracy: 0.5071 - val_loss: 2.1887 - val_accuracy: 0.4512
Epoch 38/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.7653 - accuracy: 0.5106 - val_loss: 2.2048 - val_accuracy: 0.4439
Epoch 39/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.7789 - accuracy: 0.5092 - val_loss: 2.1481 - val_accuracy: 0.4504
Epoch 40/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.7678 - accuracy: 0.5121 - val_loss: 2.1532 - val_accuracy: 0.4522
Epoch 41/50
1563/1563 [==============================] - 9s 6ms/step - loss: 1.7436 - accuracy: 0.5183 - val_loss: 2.1563 - val_accuracy: 0.4442
Epoch 42/50
1563/1563 [==============================] - 10s 7ms/step - loss: 1.7313 - accuracy: 0.5203 - val_loss: 2.1608 - val_accuracy: 0.4522
Epoch 43/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.7368 - accuracy: 0.5186 - val_loss: 2.2174 - val_accuracy: 0.4481
Epoch 44/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.7403 - accuracy: 0.5204 - val_loss: 2.1282 - val_accuracy: 0.4556
Epoch 45/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.7317 - accuracy: 0.5182 - val_loss: 2.1600 - val_accuracy: 0.4489
Epoch 46/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.7180 - accuracy: 0.5241 - val_loss: 2.2108 - val_accuracy: 0.4428
Epoch 47/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.7078 - accuracy: 0.5236 - val_loss: 2.2150 - val_accuracy: 0.4407
Epoch 48/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.7157 - accuracy: 0.5231 - val_loss: 2.2045 - val_accuracy: 0.4512
Epoch 49/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.6957 - accuracy: 0.5281 - val_loss: 2.1564 - val_accuracy: 0.4571
Epoch 50/50
1563/1563 [==============================] - 10s 6ms/step - loss: 1.7008 - accuracy: 0.5263 - val_loss: 2.2043 - val_accuracy: 0.4457
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/e27ef19ee862658e19d9ae1b9db9f54baba045e3.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Train accuracy of the model: 52.63199806213379
Train loss of the model:  1.7007933855056763
Validation accuracy of the model:  0.4456999897956848
Validation loss of the model:  2.2042770385742188
Test Loss: 2.2042770385742188
Test Accuracy: 0.4456999897956848
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>The test accuracy is the highest and this model is the least overfitted</p>
</div>
<section id="results" class="cell markdown" id="gsZJB2sSmHjJ">
<h3>Results</h3>
</section>
<div class="cell code" data-colab="{&quot;height&quot;:750,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="lnsz1TpZmTH2" data-outputId="125acfb2-8e02-450c-c5f9-0d6f2a39cac8">
<div class="sourceCode" id="cb42"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># confusion matrix</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>y_pred_classes <span class="op">=</span> np.argmax(y_pred, axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> np.argmax(y_test, axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>confusion_mtx <span class="op">=</span> confusion_matrix(y_true, y_pred_classes) </span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>f,ax <span class="op">=</span> plt.subplots(figsize <span class="op">=</span> (<span class="dv">12</span>,<span class="dv">12</span>))</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>sns.heatmap(confusion_mtx, annot<span class="op">=</span><span class="va">True</span>, linewidths<span class="op">=</span><span class="fl">0.1</span>, cmap <span class="op">=</span> <span class="st">&quot;gist_yarg_r&quot;</span>, linecolor<span class="op">=</span><span class="st">&quot;black&quot;</span>, fmt<span class="op">=</span><span class="st">&#39;.0f&#39;</span>, ax<span class="op">=</span>ax)</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Predicted Label&quot;</span>)</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;True Label&quot;</span>)</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Confusion Matrix&quot;</span>)</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>313/313 [==============================] - 2s 4ms/step
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/8bd557905a3e1e0ff92b6f71f533ecd8932d8a76.png" /></p>
</div>
</div>
<div class="cell code" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="_b86LHU3mTKG" data-outputId="81a14c04-47f6-4df9-97ef-5cf347db78ec">
<div class="sourceCode" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(confusion_mtx)):</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Class:&quot;</span>,<span class="bu">str</span>(i))</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Number of Wrong Prediction:&quot;</span>, <span class="bu">str</span>(<span class="bu">sum</span>(confusion_mtx[i])<span class="op">-</span>confusion_mtx[i][i]), <span class="st">&quot;out of 1000&quot;</span>)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Percentage of True Prediction: </span><span class="sc">{:.2f}</span><span class="st">%&quot;</span>.<span class="bu">format</span>(confusion_mtx[i][i] <span class="op">/</span> <span class="dv">10</span>))</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;***********************************************************&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Class: 0
Number of Wrong Prediction: 27 out of 1000
Percentage of True Prediction: 7.30%
***********************************************************
Class: 1
Number of Wrong Prediction: 42 out of 1000
Percentage of True Prediction: 5.80%
***********************************************************
Class: 2
Number of Wrong Prediction: 78 out of 1000
Percentage of True Prediction: 2.20%
***********************************************************
Class: 3
Number of Wrong Prediction: 68 out of 1000
Percentage of True Prediction: 3.20%
***********************************************************
Class: 4
Number of Wrong Prediction: 60 out of 1000
Percentage of True Prediction: 4.00%
***********************************************************
Class: 5
Number of Wrong Prediction: 56 out of 1000
Percentage of True Prediction: 4.40%
***********************************************************
Class: 6
Number of Wrong Prediction: 47 out of 1000
Percentage of True Prediction: 5.30%
***********************************************************
Class: 7
Number of Wrong Prediction: 52 out of 1000
Percentage of True Prediction: 4.80%
***********************************************************
Class: 8
Number of Wrong Prediction: 48 out of 1000
Percentage of True Prediction: 5.20%
***********************************************************
Class: 9
Number of Wrong Prediction: 39 out of 1000
Percentage of True Prediction: 6.10%
***********************************************************
Class: 10
Number of Wrong Prediction: 68 out of 1000
Percentage of True Prediction: 3.20%
***********************************************************
Class: 11
Number of Wrong Prediction: 87 out of 1000
Percentage of True Prediction: 1.30%
***********************************************************
Class: 12
Number of Wrong Prediction: 62 out of 1000
Percentage of True Prediction: 3.80%
***********************************************************
Class: 13
Number of Wrong Prediction: 68 out of 1000
Percentage of True Prediction: 3.20%
***********************************************************
Class: 14
Number of Wrong Prediction: 72 out of 1000
Percentage of True Prediction: 2.80%
***********************************************************
Class: 15
Number of Wrong Prediction: 65 out of 1000
Percentage of True Prediction: 3.50%
***********************************************************
Class: 16
Number of Wrong Prediction: 58 out of 1000
Percentage of True Prediction: 4.20%
***********************************************************
Class: 17
Number of Wrong Prediction: 33 out of 1000
Percentage of True Prediction: 6.70%
***********************************************************
Class: 18
Number of Wrong Prediction: 70 out of 1000
Percentage of True Prediction: 3.00%
***********************************************************
Class: 19
Number of Wrong Prediction: 64 out of 1000
Percentage of True Prediction: 3.60%
***********************************************************
Class: 20
Number of Wrong Prediction: 26 out of 1000
Percentage of True Prediction: 7.40%
***********************************************************
Class: 21
Number of Wrong Prediction: 31 out of 1000
Percentage of True Prediction: 6.90%
***********************************************************
Class: 22
Number of Wrong Prediction: 64 out of 1000
Percentage of True Prediction: 3.60%
***********************************************************
Class: 23
Number of Wrong Prediction: 40 out of 1000
Percentage of True Prediction: 6.00%
***********************************************************
Class: 24
Number of Wrong Prediction: 37 out of 1000
Percentage of True Prediction: 6.30%
***********************************************************
Class: 25
Number of Wrong Prediction: 66 out of 1000
Percentage of True Prediction: 3.40%
***********************************************************
Class: 26
Number of Wrong Prediction: 60 out of 1000
Percentage of True Prediction: 4.00%
***********************************************************
Class: 27
Number of Wrong Prediction: 73 out of 1000
Percentage of True Prediction: 2.70%
***********************************************************
Class: 28
Number of Wrong Prediction: 30 out of 1000
Percentage of True Prediction: 7.00%
***********************************************************
Class: 29
Number of Wrong Prediction: 59 out of 1000
Percentage of True Prediction: 4.10%
***********************************************************
Class: 30
Number of Wrong Prediction: 56 out of 1000
Percentage of True Prediction: 4.40%
***********************************************************
Class: 31
Number of Wrong Prediction: 55 out of 1000
Percentage of True Prediction: 4.50%
***********************************************************
Class: 32
Number of Wrong Prediction: 63 out of 1000
Percentage of True Prediction: 3.70%
***********************************************************
Class: 33
Number of Wrong Prediction: 63 out of 1000
Percentage of True Prediction: 3.70%
***********************************************************
Class: 34
Number of Wrong Prediction: 63 out of 1000
Percentage of True Prediction: 3.70%
***********************************************************
Class: 35
Number of Wrong Prediction: 65 out of 1000
Percentage of True Prediction: 3.50%
***********************************************************
Class: 36
Number of Wrong Prediction: 61 out of 1000
Percentage of True Prediction: 3.90%
***********************************************************
Class: 37
Number of Wrong Prediction: 43 out of 1000
Percentage of True Prediction: 5.70%
***********************************************************
Class: 38
Number of Wrong Prediction: 77 out of 1000
Percentage of True Prediction: 2.30%
***********************************************************
Class: 39
Number of Wrong Prediction: 54 out of 1000
Percentage of True Prediction: 4.60%
***********************************************************
Class: 40
Number of Wrong Prediction: 67 out of 1000
Percentage of True Prediction: 3.30%
***********************************************************
Class: 41
Number of Wrong Prediction: 38 out of 1000
Percentage of True Prediction: 6.20%
***********************************************************
Class: 42
Number of Wrong Prediction: 58 out of 1000
Percentage of True Prediction: 4.20%
***********************************************************
Class: 43
Number of Wrong Prediction: 60 out of 1000
Percentage of True Prediction: 4.00%
***********************************************************
Class: 44
Number of Wrong Prediction: 89 out of 1000
Percentage of True Prediction: 1.10%
***********************************************************
Class: 45
Number of Wrong Prediction: 77 out of 1000
Percentage of True Prediction: 2.30%
***********************************************************
Class: 46
Number of Wrong Prediction: 71 out of 1000
Percentage of True Prediction: 2.90%
***********************************************************
Class: 47
Number of Wrong Prediction: 46 out of 1000
Percentage of True Prediction: 5.40%
***********************************************************
Class: 48
Number of Wrong Prediction: 28 out of 1000
Percentage of True Prediction: 7.20%
***********************************************************
Class: 49
Number of Wrong Prediction: 32 out of 1000
Percentage of True Prediction: 6.80%
***********************************************************
Class: 50
Number of Wrong Prediction: 84 out of 1000
Percentage of True Prediction: 1.60%
***********************************************************
Class: 51
Number of Wrong Prediction: 60 out of 1000
Percentage of True Prediction: 4.00%
***********************************************************
Class: 52
Number of Wrong Prediction: 31 out of 1000
Percentage of True Prediction: 6.90%
***********************************************************
Class: 53
Number of Wrong Prediction: 26 out of 1000
Percentage of True Prediction: 7.40%
***********************************************************
Class: 54
Number of Wrong Prediction: 53 out of 1000
Percentage of True Prediction: 4.70%
***********************************************************
Class: 55
Number of Wrong Prediction: 88 out of 1000
Percentage of True Prediction: 1.20%
***********************************************************
Class: 56
Number of Wrong Prediction: 35 out of 1000
Percentage of True Prediction: 6.50%
***********************************************************
Class: 57
Number of Wrong Prediction: 53 out of 1000
Percentage of True Prediction: 4.70%
***********************************************************
Class: 58
Number of Wrong Prediction: 32 out of 1000
Percentage of True Prediction: 6.80%
***********************************************************
Class: 59
Number of Wrong Prediction: 62 out of 1000
Percentage of True Prediction: 3.80%
***********************************************************
Class: 60
Number of Wrong Prediction: 28 out of 1000
Percentage of True Prediction: 7.20%
***********************************************************
Class: 61
Number of Wrong Prediction: 46 out of 1000
Percentage of True Prediction: 5.40%
***********************************************************
Class: 62
Number of Wrong Prediction: 56 out of 1000
Percentage of True Prediction: 4.40%
***********************************************************
Class: 63
Number of Wrong Prediction: 69 out of 1000
Percentage of True Prediction: 3.10%
***********************************************************
Class: 64
Number of Wrong Prediction: 73 out of 1000
Percentage of True Prediction: 2.70%
***********************************************************
Class: 65
Number of Wrong Prediction: 83 out of 1000
Percentage of True Prediction: 1.70%
***********************************************************
Class: 66
Number of Wrong Prediction: 67 out of 1000
Percentage of True Prediction: 3.30%
***********************************************************
Class: 67
Number of Wrong Prediction: 61 out of 1000
Percentage of True Prediction: 3.90%
***********************************************************
Class: 68
Number of Wrong Prediction: 22 out of 1000
Percentage of True Prediction: 7.80%
***********************************************************
Class: 69
Number of Wrong Prediction: 30 out of 1000
Percentage of True Prediction: 7.00%
***********************************************************
Class: 70
Number of Wrong Prediction: 61 out of 1000
Percentage of True Prediction: 3.90%
***********************************************************
Class: 71
Number of Wrong Prediction: 36 out of 1000
Percentage of True Prediction: 6.40%
***********************************************************
Class: 72
Number of Wrong Prediction: 87 out of 1000
Percentage of True Prediction: 1.30%
***********************************************************
Class: 73
Number of Wrong Prediction: 78 out of 1000
Percentage of True Prediction: 2.20%
***********************************************************
Class: 74
Number of Wrong Prediction: 64 out of 1000
Percentage of True Prediction: 3.60%
***********************************************************
Class: 75
Number of Wrong Prediction: 32 out of 1000
Percentage of True Prediction: 6.80%
***********************************************************
Class: 76
Number of Wrong Prediction: 32 out of 1000
Percentage of True Prediction: 6.80%
***********************************************************
Class: 77
Number of Wrong Prediction: 70 out of 1000
Percentage of True Prediction: 3.00%
***********************************************************
Class: 78
Number of Wrong Prediction: 78 out of 1000
Percentage of True Prediction: 2.20%
***********************************************************
Class: 79
Number of Wrong Prediction: 59 out of 1000
Percentage of True Prediction: 4.10%
***********************************************************
Class: 80
Number of Wrong Prediction: 84 out of 1000
Percentage of True Prediction: 1.60%
***********************************************************
Class: 81
Number of Wrong Prediction: 48 out of 1000
Percentage of True Prediction: 5.20%
***********************************************************
Class: 82
Number of Wrong Prediction: 20 out of 1000
Percentage of True Prediction: 8.00%
***********************************************************
Class: 83
Number of Wrong Prediction: 75 out of 1000
Percentage of True Prediction: 2.50%
***********************************************************
Class: 84
Number of Wrong Prediction: 60 out of 1000
Percentage of True Prediction: 4.00%
***********************************************************
Class: 85
Number of Wrong Prediction: 29 out of 1000
Percentage of True Prediction: 7.10%
***********************************************************
Class: 86
Number of Wrong Prediction: 50 out of 1000
Percentage of True Prediction: 5.00%
***********************************************************
Class: 87
Number of Wrong Prediction: 42 out of 1000
Percentage of True Prediction: 5.80%
***********************************************************
Class: 88
Number of Wrong Prediction: 57 out of 1000
Percentage of True Prediction: 4.30%
***********************************************************
Class: 89
Number of Wrong Prediction: 35 out of 1000
Percentage of True Prediction: 6.50%
***********************************************************
Class: 90
Number of Wrong Prediction: 60 out of 1000
Percentage of True Prediction: 4.00%
***********************************************************
Class: 91
Number of Wrong Prediction: 50 out of 1000
Percentage of True Prediction: 5.00%
***********************************************************
Class: 92
Number of Wrong Prediction: 78 out of 1000
Percentage of True Prediction: 2.20%
***********************************************************
Class: 93
Number of Wrong Prediction: 75 out of 1000
Percentage of True Prediction: 2.50%
***********************************************************
Class: 94
Number of Wrong Prediction: 12 out of 1000
Percentage of True Prediction: 8.80%
***********************************************************
Class: 95
Number of Wrong Prediction: 49 out of 1000
Percentage of True Prediction: 5.10%
***********************************************************
Class: 96
Number of Wrong Prediction: 58 out of 1000
Percentage of True Prediction: 4.20%
***********************************************************
Class: 97
Number of Wrong Prediction: 54 out of 1000
Percentage of True Prediction: 4.60%
***********************************************************
Class: 98
Number of Wrong Prediction: 73 out of 1000
Percentage of True Prediction: 2.70%
***********************************************************
Class: 99
Number of Wrong Prediction: 62 out of 1000
Percentage of True Prediction: 3.80%
***********************************************************
</code></pre>
</div>
</div>
<section id="cifar-coarse-mode" class="cell markdown" id="GKadi96THhlq">
<h1>CIFAR COARSE MODE</h1>
</section>
<div class="cell code" id="OG0f_GznHhC0">
<div class="sourceCode" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>(X_train, y_train), (X_test, y_test) <span class="op">=</span> tf.keras.datasets.cifar100.load_data(label_mode<span class="op">=</span><span class="st">&quot;coarse&quot;</span>)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> X_train.shape <span class="op">==</span> (<span class="dv">50000</span>, <span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> X_test.shape <span class="op">==</span> (<span class="dv">10000</span>, <span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> y_train.shape <span class="op">==</span> (<span class="dv">50000</span>, <span class="dv">1</span>)</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> y_test.shape <span class="op">==</span> (<span class="dv">10000</span>, <span class="dv">1</span>)</span></code></pre></div>
</div>
<section id="data-visualization" class="cell markdown" id="4Ud9bq3ojlTG">
<h2>DATA VISUALIZATION</h2>
</section>
<div class="cell code" data-colab="{&quot;height&quot;:469,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="JuKruTJFjk0-" data-outputId="4284235b-a3c4-4f18-83d3-87bf2e0d0df0">
<div class="sourceCode" id="cb47"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> visualize_random_images(images):</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">8</span>))</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ind, img <span class="kw">in</span> <span class="bu">enumerate</span>(images[:<span class="dv">9</span>, :]):</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="bu">int</span>(<span class="st">&quot;33</span><span class="sc">%d</span><span class="st">&quot;</span> <span class="op">%</span> (ind <span class="op">+</span> <span class="dv">1</span>)))</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>        plt.imshow(img)</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>        plt.xticks([])</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>        plt.yticks([])</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>visualize_random_images(X_train)</span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/6fc65eccf4d42f47df2ca458a34549b22ec6db89.png" /></p>
</div>
</div>
<section id="data-preprocessing" class="cell markdown" id="4ZfN7F_pkvO9">
<h2>DATA PREPROCESSING</h2>
</section>
<div class="cell code" id="ODRR8MPUkzB4">
<div class="sourceCode" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># one hot encode target values</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="co"># one hot encode target values</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> to_categorical(y_train,<span class="dv">100</span>)</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> to_categorical(y_test,<span class="dv">100</span>)</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a><span class="co"># scale pixels</span></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> prep_pixels(train, test):</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># convert from integers to floats</span></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>    train_norm <span class="op">=</span> train.astype(<span class="st">&#39;float32&#39;</span>)</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>    test_norm <span class="op">=</span> test.astype(<span class="st">&#39;float32&#39;</span>)</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># normalize to range 0-1</span></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>    train_norm <span class="op">=</span> train_norm <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>    test_norm <span class="op">=</span> test_norm <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return normalized images</span></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_norm, test_norm</span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a>X_train, X_test <span class="op">=</span> prep_pixels(X_train, X_test)</span></code></pre></div>
</div>
<section id="training-and-evaluation" class="cell markdown" id="f9LXroinkvRf">
<h2>TRAINING AND EVALUATION</h2>
</section>
<div class="cell markdown">
<p>I will be doing the same thing - making 3 different baseline models and then picking the best</p>
</div>
<section id="baseline-model-1" class="cell markdown" id="57dO3fq6kvTf">
<h3>BASELINE MODEL 1</h3>
</section>
<div class="cell code" id="k73WrRqCDxyA">
<div class="sourceCode" id="cb49"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)))</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>model.add(Flatten())</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>))</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>))</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a><span class="co"># compile model</span></span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;categorical_crossentropy&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="f6p0nRGODx0f" data-outputId="36c4e07a-f143-40a5-8763-8bc03b02295e">
<div class="sourceCode" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>, batch_size<span class="op">=</span><span class="dv">32</span>, validation_data<span class="op">=</span>(X_test, y_test), verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb50-20"><a href="#cb50-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb50-21"><a href="#cb50-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb50-22"><a href="#cb50-22" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb50-23"><a href="#cb50-23" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb50-24"><a href="#cb50-24" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb50-25"><a href="#cb50-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb50-26"><a href="#cb50-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-27"><a href="#cb50-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb50-28"><a href="#cb50-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb50-29"><a href="#cb50-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb50-30"><a href="#cb50-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb50-31"><a href="#cb50-31" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb50-32"><a href="#cb50-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb50-33"><a href="#cb50-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 32, 32, 32)        896       
                                                                 
 conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      
                                                                 
 max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         
 )                                                               
                                                                 
 flatten (Flatten)           (None, 8192)              0         
                                                                 
 dense (Dense)               (None, 128)               1048704   
                                                                 
 dense_1 (Dense)             (None, 100)               12900     
                                                                 
=================================================================
Total params: 1,071,748
Trainable params: 1,071,748
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
1563/1563 [==============================] - 19s 6ms/step - loss: 2.1605 - accuracy: 0.3373 - val_loss: 1.8888 - val_accuracy: 0.4198
Epoch 2/10
1563/1563 [==============================] - 8s 5ms/step - loss: 1.6739 - accuracy: 0.4802 - val_loss: 1.7395 - val_accuracy: 0.4647
Epoch 3/10
1563/1563 [==============================] - 8s 5ms/step - loss: 1.4095 - accuracy: 0.5576 - val_loss: 1.6682 - val_accuracy: 0.4939
Epoch 4/10
1563/1563 [==============================] - 9s 6ms/step - loss: 1.1833 - accuracy: 0.6262 - val_loss: 1.7350 - val_accuracy: 0.4908
Epoch 5/10
1563/1563 [==============================] - 8s 5ms/step - loss: 0.9660 - accuracy: 0.6888 - val_loss: 1.9028 - val_accuracy: 0.4790
Epoch 6/10
1563/1563 [==============================] - 8s 5ms/step - loss: 0.7645 - accuracy: 0.7530 - val_loss: 2.1225 - val_accuracy: 0.4570
Epoch 7/10
1563/1563 [==============================] - 9s 5ms/step - loss: 0.5821 - accuracy: 0.8111 - val_loss: 2.3572 - val_accuracy: 0.4652
Epoch 8/10
1563/1563 [==============================] - 8s 5ms/step - loss: 0.4315 - accuracy: 0.8596 - val_loss: 2.7441 - val_accuracy: 0.4498
Epoch 9/10
1563/1563 [==============================] - 8s 5ms/step - loss: 0.3237 - accuracy: 0.8944 - val_loss: 3.0995 - val_accuracy: 0.4539
Epoch 10/10
1563/1563 [==============================] - 8s 5ms/step - loss: 0.2562 - accuracy: 0.9161 - val_loss: 3.5100 - val_accuracy: 0.4370
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/0d605015d2c697b6e4eee3b0dc03367a407fce82.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Train accuracy of the model: 91.61400198936462
Train loss of the model:  0.2562173008918762
Validation accuracy of the model:  0.43700000643730164
Validation loss of the model:  3.509976863861084
Test Loss: 3.509976863861084
Test Accuracy: 0.43700000643730164
</code></pre>
</div>
</div>
<section id="baseline-model-2" class="cell markdown" id="ZopxljmslBvL">
<h3>BASELINE MODEL 2</h3>
</section>
<div class="cell code" id="EbXS54twEV-W">
<div class="sourceCode" id="cb53"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)))</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>model.add(Flatten())</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>))</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>))</span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a><span class="co"># compile model</span></span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span> <span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;categorical_crossentropy&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="iPc71p00EWAm" data-outputId="04d63905-0c10-44be-e790-8d57d4e1d7e7">
<div class="sourceCode" id="cb54"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>, batch_size<span class="op">=</span><span class="dv">32</span>, validation_data<span class="op">=</span>(X_test, y_test), verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb54-18"><a href="#cb54-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-19"><a href="#cb54-19" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb54-20"><a href="#cb54-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb54-21"><a href="#cb54-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb54-22"><a href="#cb54-22" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb54-23"><a href="#cb54-23" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb54-24"><a href="#cb54-24" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb54-25"><a href="#cb54-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb54-26"><a href="#cb54-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-27"><a href="#cb54-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb54-28"><a href="#cb54-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb54-29"><a href="#cb54-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb54-30"><a href="#cb54-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb54-31"><a href="#cb54-31" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb54-32"><a href="#cb54-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb54-33"><a href="#cb54-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential_1&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_2 (Conv2D)           (None, 32, 32, 32)        896       
                                                                 
 conv2d_3 (Conv2D)           (None, 32, 32, 32)        9248      
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 16, 16, 32)       0         
 2D)                                                             
                                                                 
 conv2d_4 (Conv2D)           (None, 16, 16, 64)        18496     
                                                                 
 conv2d_5 (Conv2D)           (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_2 (MaxPooling  (None, 8, 8, 64)         0         
 2D)                                                             
                                                                 
 flatten_1 (Flatten)         (None, 4096)              0         
                                                                 
 dense_2 (Dense)             (None, 128)               524416    
                                                                 
 dense_3 (Dense)             (None, 100)               12900     
                                                                 
=================================================================
Total params: 602,884
Trainable params: 602,884
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
1563/1563 [==============================] - 10s 6ms/step - loss: 2.1956 - accuracy: 0.3283 - val_loss: 1.8694 - val_accuracy: 0.4236
Epoch 2/10
1563/1563 [==============================] - 9s 6ms/step - loss: 1.6823 - accuracy: 0.4781 - val_loss: 1.6674 - val_accuracy: 0.4870
Epoch 3/10
1563/1563 [==============================] - 9s 6ms/step - loss: 1.4320 - accuracy: 0.5492 - val_loss: 1.5614 - val_accuracy: 0.5166
Epoch 4/10
1563/1563 [==============================] - 10s 7ms/step - loss: 1.2332 - accuracy: 0.6078 - val_loss: 1.5602 - val_accuracy: 0.5259
Epoch 5/10
1563/1563 [==============================] - 11s 7ms/step - loss: 1.0555 - accuracy: 0.6612 - val_loss: 1.5654 - val_accuracy: 0.5338
Epoch 6/10
1563/1563 [==============================] - 11s 7ms/step - loss: 0.8955 - accuracy: 0.7092 - val_loss: 1.6836 - val_accuracy: 0.5224
Epoch 7/10
1563/1563 [==============================] - 9s 6ms/step - loss: 0.7441 - accuracy: 0.7560 - val_loss: 1.8552 - val_accuracy: 0.5293
Epoch 8/10
1563/1563 [==============================] - 10s 6ms/step - loss: 0.6090 - accuracy: 0.7989 - val_loss: 2.0220 - val_accuracy: 0.5069
Epoch 9/10
1563/1563 [==============================] - 10s 7ms/step - loss: 0.5013 - accuracy: 0.8313 - val_loss: 2.1814 - val_accuracy: 0.5134
Epoch 10/10
1563/1563 [==============================] - 10s 6ms/step - loss: 0.4250 - accuracy: 0.8535 - val_loss: 2.4646 - val_accuracy: 0.5099
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/1edfeb64cb6fe8670d9cecf38bf592f9365aebd9.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Train accuracy of the model: 85.34600138664246
Train loss of the model:  0.4249880909919739
Validation accuracy of the model:  0.5098999738693237
Validation loss of the model:  2.4646177291870117
Test Loss: 2.4646177291870117
Test Accuracy: 0.5098999738693237
</code></pre>
</div>
</div>
<section id="baseline-model-3" class="cell markdown" id="v2abnExrlBxf">
<h3>BASELINE MODEL 3</h3>
</section>
<div class="cell code" id="ZTwvXfT4EfAn">
<div class="sourceCode" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)))</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>model.add(Flatten())</span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>))</span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>))</span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a><span class="co"># compile model</span></span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span> <span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;categorical_crossentropy&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="idT0IvskEfC3" data-outputId="c887f859-d159-46e1-a67a-acbadf883f4f">
<div class="sourceCode" id="cb58"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>, batch_size<span class="op">=</span><span class="dv">32</span>, validation_data<span class="op">=</span>(X_test, y_test), verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb58-16"><a href="#cb58-16" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb58-17"><a href="#cb58-17" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb58-18"><a href="#cb58-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-19"><a href="#cb58-19" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb58-20"><a href="#cb58-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb58-21"><a href="#cb58-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb58-22"><a href="#cb58-22" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb58-23"><a href="#cb58-23" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb58-24"><a href="#cb58-24" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb58-25"><a href="#cb58-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb58-26"><a href="#cb58-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-27"><a href="#cb58-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb58-28"><a href="#cb58-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb58-29"><a href="#cb58-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb58-30"><a href="#cb58-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb58-31"><a href="#cb58-31" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb58-32"><a href="#cb58-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb58-33"><a href="#cb58-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential_2&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_6 (Conv2D)           (None, 32, 32, 32)        896       
                                                                 
 conv2d_7 (Conv2D)           (None, 32, 32, 32)        9248      
                                                                 
 max_pooling2d_3 (MaxPooling  (None, 16, 16, 32)       0         
 2D)                                                             
                                                                 
 conv2d_8 (Conv2D)           (None, 16, 16, 64)        18496     
                                                                 
 conv2d_9 (Conv2D)           (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_4 (MaxPooling  (None, 8, 8, 64)         0         
 2D)                                                             
                                                                 
 conv2d_10 (Conv2D)          (None, 8, 8, 128)         73856     
                                                                 
 conv2d_11 (Conv2D)          (None, 8, 8, 128)         147584    
                                                                 
 max_pooling2d_5 (MaxPooling  (None, 4, 4, 128)        0         
 2D)                                                             
                                                                 
 flatten_2 (Flatten)         (None, 2048)              0         
                                                                 
 dense_4 (Dense)             (None, 128)               262272    
                                                                 
 dense_5 (Dense)             (None, 100)               12900     
                                                                 
=================================================================
Total params: 562,180
Trainable params: 562,180
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
1563/1563 [==============================] - 12s 7ms/step - loss: 2.3399 - accuracy: 0.2820 - val_loss: 2.0067 - val_accuracy: 0.3764
Epoch 2/10
1563/1563 [==============================] - 12s 7ms/step - loss: 1.8186 - accuracy: 0.4329 - val_loss: 1.6876 - val_accuracy: 0.4702
Epoch 3/10
1563/1563 [==============================] - 10s 6ms/step - loss: 1.5383 - accuracy: 0.5147 - val_loss: 1.5797 - val_accuracy: 0.5098
Epoch 4/10
1563/1563 [==============================] - 10s 6ms/step - loss: 1.3403 - accuracy: 0.5723 - val_loss: 1.4742 - val_accuracy: 0.5386
Epoch 5/10
1563/1563 [==============================] - 9s 6ms/step - loss: 1.1733 - accuracy: 0.6226 - val_loss: 1.5349 - val_accuracy: 0.5391
Epoch 6/10
1563/1563 [==============================] - 9s 6ms/step - loss: 1.0143 - accuracy: 0.6743 - val_loss: 1.5476 - val_accuracy: 0.5489
Epoch 7/10
1563/1563 [==============================] - 9s 6ms/step - loss: 0.8782 - accuracy: 0.7134 - val_loss: 1.6020 - val_accuracy: 0.5416
Epoch 8/10
1563/1563 [==============================] - 10s 6ms/step - loss: 0.7471 - accuracy: 0.7534 - val_loss: 1.6786 - val_accuracy: 0.5330
Epoch 9/10
1563/1563 [==============================] - 9s 6ms/step - loss: 0.6398 - accuracy: 0.7857 - val_loss: 1.7862 - val_accuracy: 0.5360
Epoch 10/10
1563/1563 [==============================] - 10s 6ms/step - loss: 0.5592 - accuracy: 0.8122 - val_loss: 1.9151 - val_accuracy: 0.5339
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/918d646747338c55f6363a7230a711bd7c1c46f0.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Train accuracy of the model: 81.22000098228455
Train loss of the model:  0.5592138171195984
Validation accuracy of the model:  0.5339000225067139
Validation loss of the model:  1.9151005744934082
Test Loss: 1.9151005744934082
Test Accuracy: 0.5339000225067139
</code></pre>
</div>
</div>
<div class="cell markdown" id="WmobY21sSlAC">
<p>Baseline Model 3 has the highest test and validation accuracy but there is is stil room for improvement to reduce the overfitting</p>
</div>
<section id="improving-the-model" class="cell markdown" id="YsMInq32lNXA">
<h2>IMPROVING THE MODEL</h2>
</section>
<section id="dropout" class="cell markdown" id="fMZ-UNRHlRHK">
<h3>DROPOUT</h3>
</section>
<div class="cell code" id="bMFjdFOJEtCR">
<div class="sourceCode" id="cb61"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)))</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a>model.add(Flatten())</span>
<span id="cb61-15"><a href="#cb61-15" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>))</span>
<span id="cb61-16"><a href="#cb61-16" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb61-17"><a href="#cb61-17" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>))</span>
<span id="cb61-18"><a href="#cb61-18" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span> <span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;categorical_crossentropy&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="PyjKyGsDEtEs" data-outputId="5a6436b5-0fa7-4e93-dc53-38cf66f89062">
<div class="sourceCode" id="cb62"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">10</span>, batch_size<span class="op">=</span><span class="dv">32</span>, validation_data<span class="op">=</span>(X_test, y_test), verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb62-17"><a href="#cb62-17" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb62-18"><a href="#cb62-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-19"><a href="#cb62-19" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb62-20"><a href="#cb62-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb62-21"><a href="#cb62-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb62-22"><a href="#cb62-22" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb62-23"><a href="#cb62-23" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb62-24"><a href="#cb62-24" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb62-25"><a href="#cb62-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb62-26"><a href="#cb62-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-27"><a href="#cb62-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb62-28"><a href="#cb62-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb62-29"><a href="#cb62-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb62-30"><a href="#cb62-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb62-31"><a href="#cb62-31" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb62-32"><a href="#cb62-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb62-33"><a href="#cb62-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential_3&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_12 (Conv2D)          (None, 32, 32, 32)        896       
                                                                 
 conv2d_13 (Conv2D)          (None, 32, 32, 32)        9248      
                                                                 
 max_pooling2d_6 (MaxPooling  (None, 16, 16, 32)       0         
 2D)                                                             
                                                                 
 dropout (Dropout)           (None, 16, 16, 32)        0         
                                                                 
 conv2d_14 (Conv2D)          (None, 16, 16, 64)        18496     
                                                                 
 conv2d_15 (Conv2D)          (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_7 (MaxPooling  (None, 8, 8, 64)         0         
 2D)                                                             
                                                                 
 dropout_1 (Dropout)         (None, 8, 8, 64)          0         
                                                                 
 conv2d_16 (Conv2D)          (None, 8, 8, 128)         73856     
                                                                 
 conv2d_17 (Conv2D)          (None, 8, 8, 128)         147584    
                                                                 
 max_pooling2d_8 (MaxPooling  (None, 4, 4, 128)        0         
 2D)                                                             
                                                                 
 dropout_2 (Dropout)         (None, 4, 4, 128)         0         
                                                                 
 flatten_3 (Flatten)         (None, 2048)              0         
                                                                 
 dense_6 (Dense)             (None, 128)               262272    
                                                                 
 dropout_3 (Dropout)         (None, 128)               0         
                                                                 
 dense_7 (Dense)             (None, 100)               12900     
                                                                 
=================================================================
Total params: 562,180
Trainable params: 562,180
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
1563/1563 [==============================] - 12s 7ms/step - loss: 2.5125 - accuracy: 0.2319 - val_loss: 2.1297 - val_accuracy: 0.3388
Epoch 2/10
1563/1563 [==============================] - 10s 6ms/step - loss: 2.0684 - accuracy: 0.3580 - val_loss: 1.9401 - val_accuracy: 0.4035
Epoch 3/10
1563/1563 [==============================] - 10s 6ms/step - loss: 1.8584 - accuracy: 0.4210 - val_loss: 1.7867 - val_accuracy: 0.4420
Epoch 4/10
1563/1563 [==============================] - 10s 6ms/step - loss: 1.7179 - accuracy: 0.4619 - val_loss: 1.5990 - val_accuracy: 0.4932
Epoch 5/10
1563/1563 [==============================] - 10s 6ms/step - loss: 1.6129 - accuracy: 0.4918 - val_loss: 1.5408 - val_accuracy: 0.5138
Epoch 6/10
1563/1563 [==============================] - 10s 6ms/step - loss: 1.5386 - accuracy: 0.5146 - val_loss: 1.5645 - val_accuracy: 0.5079
Epoch 7/10
1563/1563 [==============================] - 10s 6ms/step - loss: 1.4719 - accuracy: 0.5342 - val_loss: 1.5011 - val_accuracy: 0.5298
Epoch 8/10
1563/1563 [==============================] - 10s 6ms/step - loss: 1.4158 - accuracy: 0.5494 - val_loss: 1.3898 - val_accuracy: 0.5642
Epoch 9/10
1563/1563 [==============================] - 10s 6ms/step - loss: 1.3715 - accuracy: 0.5622 - val_loss: 1.4455 - val_accuracy: 0.5530
Epoch 10/10
1563/1563 [==============================] - 10s 6ms/step - loss: 1.3485 - accuracy: 0.5684 - val_loss: 1.4364 - val_accuracy: 0.5497
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/22d65235b3524c0983c508eb4686712be69a8ad2.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Train accuracy of the model: 56.84000253677368
Train loss of the model:  1.3484593629837036
Validation accuracy of the model:  0.5497000217437744
Validation loss of the model:  1.4363957643508911
Test Loss: 1.4363957643508911
Test Accuracy: 0.5497000217437744
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>The test accuracy is not really different from baseline model 3 that does not have dropout but since the model's performance does improve with increasing epoch lets try to fit the model with a larger number of epoch</p>
</div>
<div class="cell code" data-execution_count="2" id="wRQOwN3qGq1y">
<div class="sourceCode" id="cb65"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fitting with 40 epoch</span></span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="Y2QneHOWG1wq" data-outputId="0d0eedee-0436-4650-9b00-4676fa56844e">
<div class="sourceCode" id="cb66"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">40</span>, batch_size<span class="op">=</span><span class="dv">32</span>, validation_data<span class="op">=</span>(X_test, y_test), verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb66-14"><a href="#cb66-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb66-15"><a href="#cb66-15" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb66-16"><a href="#cb66-16" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb66-17"><a href="#cb66-17" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb66-18"><a href="#cb66-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-19"><a href="#cb66-19" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb66-20"><a href="#cb66-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb66-21"><a href="#cb66-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb66-22"><a href="#cb66-22" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb66-23"><a href="#cb66-23" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb66-24"><a href="#cb66-24" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb66-25"><a href="#cb66-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb66-26"><a href="#cb66-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-27"><a href="#cb66-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb66-28"><a href="#cb66-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb66-29"><a href="#cb66-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb66-30"><a href="#cb66-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb66-31"><a href="#cb66-31" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb66-32"><a href="#cb66-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb66-33"><a href="#cb66-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential_3&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_12 (Conv2D)          (None, 32, 32, 32)        896       
                                                                 
 conv2d_13 (Conv2D)          (None, 32, 32, 32)        9248      
                                                                 
 max_pooling2d_6 (MaxPooling  (None, 16, 16, 32)       0         
 2D)                                                             
                                                                 
 dropout (Dropout)           (None, 16, 16, 32)        0         
                                                                 
 conv2d_14 (Conv2D)          (None, 16, 16, 64)        18496     
                                                                 
 conv2d_15 (Conv2D)          (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_7 (MaxPooling  (None, 8, 8, 64)         0         
 2D)                                                             
                                                                 
 dropout_1 (Dropout)         (None, 8, 8, 64)          0         
                                                                 
 conv2d_16 (Conv2D)          (None, 8, 8, 128)         73856     
                                                                 
 conv2d_17 (Conv2D)          (None, 8, 8, 128)         147584    
                                                                 
 max_pooling2d_8 (MaxPooling  (None, 4, 4, 128)        0         
 2D)                                                             
                                                                 
 dropout_2 (Dropout)         (None, 4, 4, 128)         0         
                                                                 
 flatten_3 (Flatten)         (None, 2048)              0         
                                                                 
 dense_6 (Dense)             (None, 128)               262272    
                                                                 
 dropout_3 (Dropout)         (None, 128)               0         
                                                                 
 dense_7 (Dense)             (None, 100)               12900     
                                                                 
=================================================================
Total params: 562,180
Trainable params: 562,180
Non-trainable params: 0
_________________________________________________________________
Epoch 1/40
1563/1563 [==============================] - 10s 7ms/step - loss: 1.3156 - accuracy: 0.5803 - val_loss: 1.3951 - val_accuracy: 0.5632
Epoch 2/40
1563/1563 [==============================] - 10s 7ms/step - loss: 1.2785 - accuracy: 0.5865 - val_loss: 1.3809 - val_accuracy: 0.5692
Epoch 3/40
1563/1563 [==============================] - 10s 7ms/step - loss: 1.2581 - accuracy: 0.5943 - val_loss: 1.3643 - val_accuracy: 0.5703
Epoch 4/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.2223 - accuracy: 0.6064 - val_loss: 1.4043 - val_accuracy: 0.5656
Epoch 5/40
1563/1563 [==============================] - 10s 7ms/step - loss: 1.2167 - accuracy: 0.6081 - val_loss: 1.3836 - val_accuracy: 0.5713
Epoch 6/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.1887 - accuracy: 0.6159 - val_loss: 1.4423 - val_accuracy: 0.5597
Epoch 7/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.1805 - accuracy: 0.6200 - val_loss: 1.3711 - val_accuracy: 0.5711
Epoch 8/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.1590 - accuracy: 0.6273 - val_loss: 1.3246 - val_accuracy: 0.5827
Epoch 9/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.1445 - accuracy: 0.6312 - val_loss: 1.3241 - val_accuracy: 0.5874
Epoch 10/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.1297 - accuracy: 0.6340 - val_loss: 1.3704 - val_accuracy: 0.5821
Epoch 11/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.1195 - accuracy: 0.6346 - val_loss: 1.3340 - val_accuracy: 0.5966
Epoch 12/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0986 - accuracy: 0.6428 - val_loss: 1.4197 - val_accuracy: 0.5743
Epoch 13/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0898 - accuracy: 0.6485 - val_loss: 1.3399 - val_accuracy: 0.5939
Epoch 14/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0912 - accuracy: 0.6449 - val_loss: 1.3349 - val_accuracy: 0.5935
Epoch 15/40
1563/1563 [==============================] - 10s 7ms/step - loss: 1.0772 - accuracy: 0.6500 - val_loss: 1.3569 - val_accuracy: 0.5879
Epoch 16/40
1563/1563 [==============================] - 11s 7ms/step - loss: 1.0738 - accuracy: 0.6525 - val_loss: 1.3685 - val_accuracy: 0.5834
Epoch 17/40
1563/1563 [==============================] - 10s 7ms/step - loss: 1.0605 - accuracy: 0.6569 - val_loss: 1.3603 - val_accuracy: 0.5877
Epoch 18/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0506 - accuracy: 0.6586 - val_loss: 1.3482 - val_accuracy: 0.5906
Epoch 19/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0472 - accuracy: 0.6569 - val_loss: 1.3300 - val_accuracy: 0.5948
Epoch 20/40
1563/1563 [==============================] - 10s 7ms/step - loss: 1.0336 - accuracy: 0.6626 - val_loss: 1.3613 - val_accuracy: 0.5855
Epoch 21/40
1563/1563 [==============================] - 10s 7ms/step - loss: 1.0241 - accuracy: 0.6676 - val_loss: 1.3573 - val_accuracy: 0.5879
Epoch 22/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0222 - accuracy: 0.6688 - val_loss: 1.3509 - val_accuracy: 0.5972
Epoch 23/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0218 - accuracy: 0.6660 - val_loss: 1.3206 - val_accuracy: 0.6012
Epoch 24/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0033 - accuracy: 0.6731 - val_loss: 1.3213 - val_accuracy: 0.6009
Epoch 25/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0035 - accuracy: 0.6711 - val_loss: 1.3610 - val_accuracy: 0.5910
Epoch 26/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0060 - accuracy: 0.6715 - val_loss: 1.4098 - val_accuracy: 0.5828
Epoch 27/40
1563/1563 [==============================] - 10s 6ms/step - loss: 0.9835 - accuracy: 0.6814 - val_loss: 1.3662 - val_accuracy: 0.5909
Epoch 28/40
1563/1563 [==============================] - 10s 6ms/step - loss: 0.9944 - accuracy: 0.6766 - val_loss: 1.3815 - val_accuracy: 0.5947
Epoch 29/40
1563/1563 [==============================] - 10s 6ms/step - loss: 0.9819 - accuracy: 0.6821 - val_loss: 1.3448 - val_accuracy: 0.5962
Epoch 30/40
1563/1563 [==============================] - 10s 6ms/step - loss: 0.9876 - accuracy: 0.6821 - val_loss: 1.3723 - val_accuracy: 0.5896
Epoch 31/40
1563/1563 [==============================] - 10s 6ms/step - loss: 0.9800 - accuracy: 0.6816 - val_loss: 1.3563 - val_accuracy: 0.5952
Epoch 32/40
1563/1563 [==============================] - 10s 6ms/step - loss: 0.9757 - accuracy: 0.6851 - val_loss: 1.3592 - val_accuracy: 0.5951
Epoch 33/40
1563/1563 [==============================] - 10s 6ms/step - loss: 0.9637 - accuracy: 0.6876 - val_loss: 1.3582 - val_accuracy: 0.5982
Epoch 34/40
1563/1563 [==============================] - 10s 6ms/step - loss: 0.9662 - accuracy: 0.6863 - val_loss: 1.3669 - val_accuracy: 0.5891
Epoch 35/40
1563/1563 [==============================] - 10s 6ms/step - loss: 0.9635 - accuracy: 0.6871 - val_loss: 1.3901 - val_accuracy: 0.5888
Epoch 36/40
1563/1563 [==============================] - 10s 6ms/step - loss: 0.9585 - accuracy: 0.6900 - val_loss: 1.3505 - val_accuracy: 0.5984
Epoch 37/40
1563/1563 [==============================] - 11s 7ms/step - loss: 0.9456 - accuracy: 0.6932 - val_loss: 1.3364 - val_accuracy: 0.6062
Epoch 38/40
1563/1563 [==============================] - 10s 6ms/step - loss: 0.9526 - accuracy: 0.6911 - val_loss: 1.3403 - val_accuracy: 0.6086
Epoch 39/40
1563/1563 [==============================] - 10s 6ms/step - loss: 0.9471 - accuracy: 0.6919 - val_loss: 1.3863 - val_accuracy: 0.5891
Epoch 40/40
1563/1563 [==============================] - 10s 6ms/step - loss: 0.9435 - accuracy: 0.6936 - val_loss: 1.3909 - val_accuracy: 0.5917
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/3ef928fd60924b4bcc57ef28370d960d9816f91e.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Train accuracy of the model: 69.35799717903137
Train loss of the model:  0.9434699416160583
Validation accuracy of the model:  0.59170001745224
Validation loss of the model:  1.39094877243042
Test Loss: 1.39094877243042
Test Accuracy: 0.59170001745224
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>The test accuracy si now much higher compared to baseline model 3</p>
</div>
<section id="dropout--data-augmentation" class="cell markdown" id="OSHit25pFBAw">
<h3>DROPOUT + DATA AUGMENTATION</h3>
</section>
<div class="cell code" id="Hrz3qJhUFKJY">
<div class="sourceCode" id="cb69"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)))</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb69-13"><a href="#cb69-13" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb69-14"><a href="#cb69-14" aria-hidden="true" tabindex="-1"></a>model.add(Flatten())</span>
<span id="cb69-15"><a href="#cb69-15" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>))</span>
<span id="cb69-16"><a href="#cb69-16" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb69-17"><a href="#cb69-17" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>))</span>
<span id="cb69-18"><a href="#cb69-18" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span> <span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;categorical_crossentropy&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" id="sYVzzObvFhbW">
<div class="sourceCode" id="cb70"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.preprocessing.image <span class="im">import</span> ImageDataGenerator</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>datagen <span class="op">=</span> ImageDataGenerator(</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>        featurewise_center<span class="op">=</span><span class="va">False</span>,  <span class="co"># set input mean to 0 over the dataset</span></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>        samplewise_center<span class="op">=</span><span class="va">False</span>,  <span class="co"># set each sample mean to 0</span></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a>        featurewise_std_normalization<span class="op">=</span><span class="va">False</span>,  <span class="co"># divide inputs by std of the dataset</span></span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a>        samplewise_std_normalization<span class="op">=</span><span class="va">False</span>,  <span class="co"># divide each input by its std</span></span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a>        zca_whitening<span class="op">=</span><span class="va">False</span>,  <span class="co"># dimesion reduction</span></span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>        rotation_range<span class="op">=</span><span class="fl">0.1</span>,  <span class="co"># randomly rotate images in the range</span></span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>        zoom_range <span class="op">=</span> <span class="fl">0.1</span>, <span class="co"># Randomly zoom image</span></span>
<span id="cb70-10"><a href="#cb70-10" aria-hidden="true" tabindex="-1"></a>        width_shift_range<span class="op">=</span><span class="fl">0.1</span>,  <span class="co"># randomly shift images horizontally</span></span>
<span id="cb70-11"><a href="#cb70-11" aria-hidden="true" tabindex="-1"></a>        height_shift_range<span class="op">=</span><span class="fl">0.1</span>,  <span class="co"># randomly shift images vertically</span></span>
<span id="cb70-12"><a href="#cb70-12" aria-hidden="true" tabindex="-1"></a>        horizontal_flip<span class="op">=</span><span class="va">False</span>,  <span class="co"># randomly flip images</span></span>
<span id="cb70-13"><a href="#cb70-13" aria-hidden="true" tabindex="-1"></a>        vertical_flip<span class="op">=</span><span class="va">False</span>)  <span class="co"># randomly flip images</span></span>
<span id="cb70-14"><a href="#cb70-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-15"><a href="#cb70-15" aria-hidden="true" tabindex="-1"></a>datagen.fit(X_train)</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="jZULNzKkFKqe" data-outputId="c6ce4c89-cae1-455e-8edd-b487a4603fe0">
<div class="sourceCode" id="cb71"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit_generator(datagen.flow(X_train, y_train, batch_size<span class="op">=</span><span class="dv">32</span>),shuffle<span class="op">=</span><span class="va">True</span>, epochs<span class="op">=</span><span class="dv">10</span>, validation_data <span class="op">=</span> (X_test, y_test),</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>                              verbose <span class="op">=</span> <span class="dv">2</span>, steps_per_epoch<span class="op">=</span>X_train.shape[<span class="dv">0</span>] <span class="op">//</span> <span class="dv">100</span>)</span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb71-13"><a href="#cb71-13" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb71-14"><a href="#cb71-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb71-15"><a href="#cb71-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb71-16"><a href="#cb71-16" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb71-17"><a href="#cb71-17" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb71-18"><a href="#cb71-18" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb71-19"><a href="#cb71-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-20"><a href="#cb71-20" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb71-21"><a href="#cb71-21" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb71-22"><a href="#cb71-22" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb71-23"><a href="#cb71-23" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb71-24"><a href="#cb71-24" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb71-25"><a href="#cb71-25" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb71-26"><a href="#cb71-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb71-27"><a href="#cb71-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-28"><a href="#cb71-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb71-29"><a href="#cb71-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb71-30"><a href="#cb71-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb71-31"><a href="#cb71-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb71-32"><a href="#cb71-32" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb71-33"><a href="#cb71-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb71-34"><a href="#cb71-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential_5&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_24 (Conv2D)          (None, 32, 32, 32)        896       
                                                                 
 conv2d_25 (Conv2D)          (None, 32, 32, 32)        9248      
                                                                 
 max_pooling2d_12 (MaxPoolin  (None, 16, 16, 32)       0         
 g2D)                                                            
                                                                 
 dropout_8 (Dropout)         (None, 16, 16, 32)        0         
                                                                 
 conv2d_26 (Conv2D)          (None, 16, 16, 64)        18496     
                                                                 
 conv2d_27 (Conv2D)          (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_13 (MaxPoolin  (None, 8, 8, 64)         0         
 g2D)                                                            
                                                                 
 dropout_9 (Dropout)         (None, 8, 8, 64)          0         
                                                                 
 conv2d_28 (Conv2D)          (None, 8, 8, 128)         73856     
                                                                 
 conv2d_29 (Conv2D)          (None, 8, 8, 128)         147584    
                                                                 
 max_pooling2d_14 (MaxPoolin  (None, 4, 4, 128)        0         
 g2D)                                                            
                                                                 
 dropout_10 (Dropout)        (None, 4, 4, 128)         0         
                                                                 
 flatten_5 (Flatten)         (None, 2048)              0         
                                                                 
 dense_10 (Dense)            (None, 128)               262272    
                                                                 
 dropout_11 (Dropout)        (None, 128)               0         
                                                                 
 dense_11 (Dense)            (None, 100)               12900     
                                                                 
=================================================================
Total params: 562,180
Trainable params: 562,180
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
500/500 - 13s - loss: 2.9052 - accuracy: 0.1203 - val_loss: 2.6183 - val_accuracy: 0.1921 - 13s/epoch - 27ms/step
Epoch 2/10
500/500 - 13s - loss: 2.5538 - accuracy: 0.2134 - val_loss: 2.3904 - val_accuracy: 0.2491 - 13s/epoch - 25ms/step
Epoch 3/10
500/500 - 10s - loss: 2.3870 - accuracy: 0.2614 - val_loss: 2.2454 - val_accuracy: 0.2951 - 10s/epoch - 20ms/step
Epoch 4/10
500/500 - 10s - loss: 2.2696 - accuracy: 0.2984 - val_loss: 2.1703 - val_accuracy: 0.3222 - 10s/epoch - 19ms/step
Epoch 5/10
500/500 - 10s - loss: 2.2107 - accuracy: 0.3131 - val_loss: 2.0980 - val_accuracy: 0.3419 - 10s/epoch - 20ms/step
Epoch 6/10
500/500 - 10s - loss: 2.1561 - accuracy: 0.3303 - val_loss: 2.0753 - val_accuracy: 0.3524 - 10s/epoch - 20ms/step
Epoch 7/10
500/500 - 10s - loss: 2.0887 - accuracy: 0.3548 - val_loss: 1.9531 - val_accuracy: 0.3845 - 10s/epoch - 20ms/step
Epoch 8/10
500/500 - 10s - loss: 2.0325 - accuracy: 0.3680 - val_loss: 1.9147 - val_accuracy: 0.4037 - 10s/epoch - 20ms/step
Epoch 9/10
500/500 - 10s - loss: 2.0100 - accuracy: 0.3710 - val_loss: 1.8461 - val_accuracy: 0.4205 - 10s/epoch - 20ms/step
Epoch 10/10
500/500 - 10s - loss: 1.9646 - accuracy: 0.3862 - val_loss: 1.8658 - val_accuracy: 0.4120 - 10s/epoch - 19ms/step
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/d40ae43f2ebd744f51e5943fa1317d397c194463.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Train accuracy of the model: 38.618749380111694
Train loss of the model:  1.964614987373352
Validation accuracy of the model:  0.41200000047683716
Validation loss of the model:  1.8657792806625366
Test Loss: 1.8657792806625366
Test Accuracy: 0.41200000047683716
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Since the model does improve with increasing epoch, let's try to increase the epoch</p>
</div>
<div class="cell code" data-execution_count="3" id="_d1zIRlEJlqV">
<div class="sourceCode" id="cb74"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fitting with 30 epoch</span></span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="yPL6PPYbKBAz" data-outputId="e0f54e5d-6a9d-471d-d2de-3a648be7cf4e">
<div class="sourceCode" id="cb75"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit_generator(datagen.flow(X_train, y_train, batch_size<span class="op">=</span><span class="dv">32</span>),shuffle<span class="op">=</span><span class="va">True</span>, epochs<span class="op">=</span><span class="dv">30</span>, validation_data <span class="op">=</span> (X_test, y_test),</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>                              verbose <span class="op">=</span> <span class="dv">2</span>, steps_per_epoch<span class="op">=</span>X_train.shape[<span class="dv">0</span>] <span class="op">//</span> <span class="dv">100</span>)</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb75-13"><a href="#cb75-13" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb75-14"><a href="#cb75-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb75-15"><a href="#cb75-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb75-16"><a href="#cb75-16" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb75-17"><a href="#cb75-17" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb75-18"><a href="#cb75-18" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb75-19"><a href="#cb75-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-20"><a href="#cb75-20" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb75-21"><a href="#cb75-21" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb75-22"><a href="#cb75-22" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb75-23"><a href="#cb75-23" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb75-24"><a href="#cb75-24" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb75-25"><a href="#cb75-25" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb75-26"><a href="#cb75-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb75-27"><a href="#cb75-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-28"><a href="#cb75-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb75-29"><a href="#cb75-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb75-30"><a href="#cb75-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb75-31"><a href="#cb75-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb75-32"><a href="#cb75-32" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb75-33"><a href="#cb75-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb75-34"><a href="#cb75-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential_7&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_36 (Conv2D)          (None, 32, 32, 32)        896       
                                                                 
 conv2d_37 (Conv2D)          (None, 32, 32, 32)        9248      
                                                                 
 max_pooling2d_18 (MaxPoolin  (None, 16, 16, 32)       0         
 g2D)                                                            
                                                                 
 dropout_16 (Dropout)        (None, 16, 16, 32)        0         
                                                                 
 conv2d_38 (Conv2D)          (None, 16, 16, 64)        18496     
                                                                 
 conv2d_39 (Conv2D)          (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_19 (MaxPoolin  (None, 8, 8, 64)         0         
 g2D)                                                            
                                                                 
 dropout_17 (Dropout)        (None, 8, 8, 64)          0         
                                                                 
 conv2d_40 (Conv2D)          (None, 8, 8, 128)         73856     
                                                                 
 conv2d_41 (Conv2D)          (None, 8, 8, 128)         147584    
                                                                 
 max_pooling2d_20 (MaxPoolin  (None, 4, 4, 128)        0         
 g2D)                                                            
                                                                 
 dropout_18 (Dropout)        (None, 4, 4, 128)         0         
                                                                 
 flatten_7 (Flatten)         (None, 2048)              0         
                                                                 
 dense_14 (Dense)            (None, 128)               262272    
                                                                 
 dropout_19 (Dropout)        (None, 128)               0         
                                                                 
 dense_15 (Dense)            (None, 100)               12900     
                                                                 
=================================================================
Total params: 562,180
Trainable params: 562,180
Non-trainable params: 0
_________________________________________________________________
Epoch 1/30
500/500 - 11s - loss: 2.9063 - accuracy: 0.1276 - val_loss: 2.6466 - val_accuracy: 0.1973 - 11s/epoch - 22ms/step
Epoch 2/30
500/500 - 10s - loss: 2.5525 - accuracy: 0.2093 - val_loss: 2.4005 - val_accuracy: 0.2706 - 10s/epoch - 20ms/step
Epoch 3/30
500/500 - 10s - loss: 2.4104 - accuracy: 0.2521 - val_loss: 2.3073 - val_accuracy: 0.2882 - 10s/epoch - 20ms/step
Epoch 4/30
500/500 - 10s - loss: 2.2962 - accuracy: 0.2913 - val_loss: 2.2051 - val_accuracy: 0.3135 - 10s/epoch - 19ms/step
Epoch 5/30
500/500 - 10s - loss: 2.2102 - accuracy: 0.3158 - val_loss: 2.0423 - val_accuracy: 0.3685 - 10s/epoch - 20ms/step
Epoch 6/30
500/500 - 10s - loss: 2.1306 - accuracy: 0.3388 - val_loss: 2.0116 - val_accuracy: 0.3697 - 10s/epoch - 20ms/step
Epoch 7/30
500/500 - 10s - loss: 2.0776 - accuracy: 0.3560 - val_loss: 1.9046 - val_accuracy: 0.4042 - 10s/epoch - 20ms/step
Epoch 8/30
500/500 - 10s - loss: 2.0304 - accuracy: 0.3704 - val_loss: 1.9205 - val_accuracy: 0.3989 - 10s/epoch - 20ms/step
Epoch 9/30
500/500 - 10s - loss: 2.0053 - accuracy: 0.3796 - val_loss: 1.8537 - val_accuracy: 0.4231 - 10s/epoch - 21ms/step
Epoch 10/30
500/500 - 10s - loss: 1.9404 - accuracy: 0.3934 - val_loss: 1.8527 - val_accuracy: 0.4243 - 10s/epoch - 20ms/step
Epoch 11/30
500/500 - 10s - loss: 1.9148 - accuracy: 0.4037 - val_loss: 1.7991 - val_accuracy: 0.4320 - 10s/epoch - 20ms/step
Epoch 12/30
500/500 - 10s - loss: 1.9014 - accuracy: 0.4095 - val_loss: 1.7994 - val_accuracy: 0.4345 - 10s/epoch - 20ms/step
Epoch 13/30
500/500 - 10s - loss: 1.8602 - accuracy: 0.4206 - val_loss: 1.7552 - val_accuracy: 0.4459 - 10s/epoch - 19ms/step
Epoch 14/30
500/500 - 10s - loss: 1.8280 - accuracy: 0.4310 - val_loss: 1.7015 - val_accuracy: 0.4679 - 10s/epoch - 19ms/step
Epoch 15/30
500/500 - 10s - loss: 1.8080 - accuracy: 0.4336 - val_loss: 1.6474 - val_accuracy: 0.4846 - 10s/epoch - 21ms/step
Epoch 16/30
500/500 - 10s - loss: 1.7883 - accuracy: 0.4392 - val_loss: 1.7098 - val_accuracy: 0.4639 - 10s/epoch - 20ms/step
Epoch 17/30
500/500 - 10s - loss: 1.7800 - accuracy: 0.4445 - val_loss: 1.6955 - val_accuracy: 0.4626 - 10s/epoch - 20ms/step
Epoch 18/30
500/500 - 10s - loss: 1.7614 - accuracy: 0.4501 - val_loss: 1.6465 - val_accuracy: 0.4817 - 10s/epoch - 20ms/step
Epoch 19/30
500/500 - 10s - loss: 1.7395 - accuracy: 0.4547 - val_loss: 1.6871 - val_accuracy: 0.4598 - 10s/epoch - 20ms/step
Epoch 20/30
500/500 - 10s - loss: 1.7086 - accuracy: 0.4697 - val_loss: 1.5912 - val_accuracy: 0.5002 - 10s/epoch - 19ms/step
Epoch 21/30
500/500 - 10s - loss: 1.7002 - accuracy: 0.4720 - val_loss: 1.5687 - val_accuracy: 0.5049 - 10s/epoch - 20ms/step
Epoch 22/30
500/500 - 10s - loss: 1.6729 - accuracy: 0.4735 - val_loss: 1.5411 - val_accuracy: 0.5090 - 10s/epoch - 20ms/step
Epoch 23/30
500/500 - 10s - loss: 1.6887 - accuracy: 0.4706 - val_loss: 1.5705 - val_accuracy: 0.5027 - 10s/epoch - 20ms/step
Epoch 24/30
500/500 - 10s - loss: 1.6450 - accuracy: 0.4821 - val_loss: 1.5930 - val_accuracy: 0.4981 - 10s/epoch - 20ms/step
Epoch 25/30
500/500 - 10s - loss: 1.6422 - accuracy: 0.4842 - val_loss: 1.5821 - val_accuracy: 0.4999 - 10s/epoch - 20ms/step
Epoch 26/30
500/500 - 10s - loss: 1.6460 - accuracy: 0.4801 - val_loss: 1.5214 - val_accuracy: 0.5207 - 10s/epoch - 19ms/step
Epoch 27/30
500/500 - 10s - loss: 1.6222 - accuracy: 0.4913 - val_loss: 1.5897 - val_accuracy: 0.4998 - 10s/epoch - 20ms/step
Epoch 28/30
500/500 - 10s - loss: 1.6485 - accuracy: 0.4847 - val_loss: 1.5104 - val_accuracy: 0.5184 - 10s/epoch - 20ms/step
Epoch 29/30
500/500 - 10s - loss: 1.6125 - accuracy: 0.4905 - val_loss: 1.5650 - val_accuracy: 0.5003 - 10s/epoch - 20ms/step
Epoch 30/30
500/500 - 10s - loss: 1.6072 - accuracy: 0.4944 - val_loss: 1.5836 - val_accuracy: 0.5002 - 10s/epoch - 20ms/step
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/85878754769df2d77663a33f581e2b319706623c.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Train accuracy of the model: 49.44374859333038
Train loss of the model:  1.6071778535842896
Validation accuracy of the model:  0.5001999735832214
Validation loss of the model:  1.5835617780685425
Test Loss: 1.5835617780685425
Test Accuracy: 0.5001999735832214
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>The results seem to be good so I will continue to increase the epoch and test</p>
</div>
<div class="cell code" data-execution_count="4" id="YH_x0N0yMsbI">
<div class="sourceCode" id="cb78"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fitting in with 40 epoch</span></span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="Y-gcQIswMshi" data-outputId="807ae97b-ac4d-4ef0-ca52-a8934ecd47ea" data-scrolled="false">
<div class="sourceCode" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit_generator(datagen.flow(X_train, y_train, batch_size<span class="op">=</span><span class="dv">32</span>),shuffle<span class="op">=</span><span class="va">True</span>, epochs<span class="op">=</span><span class="dv">40</span>, validation_data <span class="op">=</span> (X_test, y_test),</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a>                              verbose <span class="op">=</span> <span class="dv">2</span>, steps_per_epoch<span class="op">=</span>X_train.shape[<span class="dv">0</span>] <span class="op">//</span> <span class="dv">100</span>)</span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-11"><a href="#cb79-11" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb79-12"><a href="#cb79-12" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb79-13"><a href="#cb79-13" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb79-14"><a href="#cb79-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb79-15"><a href="#cb79-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb79-16"><a href="#cb79-16" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb79-17"><a href="#cb79-17" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb79-18"><a href="#cb79-18" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb79-19"><a href="#cb79-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-20"><a href="#cb79-20" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb79-21"><a href="#cb79-21" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb79-22"><a href="#cb79-22" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb79-23"><a href="#cb79-23" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb79-24"><a href="#cb79-24" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb79-25"><a href="#cb79-25" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb79-26"><a href="#cb79-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb79-27"><a href="#cb79-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-28"><a href="#cb79-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb79-29"><a href="#cb79-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb79-30"><a href="#cb79-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb79-31"><a href="#cb79-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb79-32"><a href="#cb79-32" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb79-33"><a href="#cb79-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb79-34"><a href="#cb79-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential_8&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_42 (Conv2D)          (None, 32, 32, 32)        896       
                                                                 
 conv2d_43 (Conv2D)          (None, 32, 32, 32)        9248      
                                                                 
 max_pooling2d_21 (MaxPoolin  (None, 16, 16, 32)       0         
 g2D)                                                            
                                                                 
 dropout_20 (Dropout)        (None, 16, 16, 32)        0         
                                                                 
 conv2d_44 (Conv2D)          (None, 16, 16, 64)        18496     
                                                                 
 conv2d_45 (Conv2D)          (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_22 (MaxPoolin  (None, 8, 8, 64)         0         
 g2D)                                                            
                                                                 
 dropout_21 (Dropout)        (None, 8, 8, 64)          0         
                                                                 
 conv2d_46 (Conv2D)          (None, 8, 8, 128)         73856     
                                                                 
 conv2d_47 (Conv2D)          (None, 8, 8, 128)         147584    
                                                                 
 max_pooling2d_23 (MaxPoolin  (None, 4, 4, 128)        0         
 g2D)                                                            
                                                                 
 dropout_22 (Dropout)        (None, 4, 4, 128)         0         
                                                                 
 flatten_8 (Flatten)         (None, 2048)              0         
                                                                 
 dense_16 (Dense)            (None, 128)               262272    
                                                                 
 dropout_23 (Dropout)        (None, 128)               0         
                                                                 
 dense_17 (Dense)            (None, 100)               12900     
                                                                 
=================================================================
Total params: 562,180
Trainable params: 562,180
Non-trainable params: 0
_________________________________________________________________
Epoch 1/40
500/500 - 11s - loss: 2.8995 - accuracy: 0.1231 - val_loss: 2.5463 - val_accuracy: 0.2053 - 11s/epoch - 22ms/step
Epoch 2/40
500/500 - 10s - loss: 2.5294 - accuracy: 0.2124 - val_loss: 2.3598 - val_accuracy: 0.2748 - 10s/epoch - 20ms/step
Epoch 3/40
500/500 - 11s - loss: 2.3814 - accuracy: 0.2635 - val_loss: 2.2456 - val_accuracy: 0.3070 - 11s/epoch - 22ms/step
Epoch 4/40
500/500 - 15s - loss: 2.2833 - accuracy: 0.2940 - val_loss: 2.1650 - val_accuracy: 0.3298 - 15s/epoch - 31ms/step
Epoch 5/40
500/500 - 12s - loss: 2.2003 - accuracy: 0.3171 - val_loss: 2.0855 - val_accuracy: 0.3588 - 12s/epoch - 25ms/step
Epoch 6/40
500/500 - 11s - loss: 2.1628 - accuracy: 0.3302 - val_loss: 2.0228 - val_accuracy: 0.3674 - 11s/epoch - 22ms/step
Epoch 7/40
500/500 - 17s - loss: 2.0851 - accuracy: 0.3459 - val_loss: 1.9375 - val_accuracy: 0.3886 - 17s/epoch - 35ms/step
Epoch 8/40
500/500 - 10s - loss: 2.0724 - accuracy: 0.3514 - val_loss: 1.8890 - val_accuracy: 0.4065 - 10s/epoch - 20ms/step
Epoch 9/40
500/500 - 10s - loss: 2.0098 - accuracy: 0.3744 - val_loss: 1.8390 - val_accuracy: 0.4201 - 10s/epoch - 20ms/step
Epoch 10/40
500/500 - 10s - loss: 1.9641 - accuracy: 0.3878 - val_loss: 1.8311 - val_accuracy: 0.4276 - 10s/epoch - 19ms/step
Epoch 11/40
500/500 - 10s - loss: 1.9220 - accuracy: 0.4013 - val_loss: 1.7502 - val_accuracy: 0.4523 - 10s/epoch - 20ms/step
Epoch 12/40
500/500 - 10s - loss: 1.9005 - accuracy: 0.4049 - val_loss: 1.7451 - val_accuracy: 0.4501 - 10s/epoch - 21ms/step
Epoch 13/40
500/500 - 10s - loss: 1.8709 - accuracy: 0.4143 - val_loss: 1.7614 - val_accuracy: 0.4413 - 10s/epoch - 20ms/step
Epoch 14/40
500/500 - 10s - loss: 1.8514 - accuracy: 0.4238 - val_loss: 1.6898 - val_accuracy: 0.4670 - 10s/epoch - 20ms/step
Epoch 15/40
500/500 - 10s - loss: 1.7992 - accuracy: 0.4348 - val_loss: 1.7501 - val_accuracy: 0.4511 - 10s/epoch - 19ms/step
Epoch 16/40
500/500 - 10s - loss: 1.7945 - accuracy: 0.4429 - val_loss: 1.6936 - val_accuracy: 0.4631 - 10s/epoch - 20ms/step
Epoch 17/40
500/500 - 10s - loss: 1.7759 - accuracy: 0.4430 - val_loss: 1.6730 - val_accuracy: 0.4738 - 10s/epoch - 19ms/step
Epoch 18/40
500/500 - 10s - loss: 1.7516 - accuracy: 0.4520 - val_loss: 1.6635 - val_accuracy: 0.4689 - 10s/epoch - 19ms/step
Epoch 19/40
500/500 - 10s - loss: 1.7388 - accuracy: 0.4552 - val_loss: 1.6404 - val_accuracy: 0.4903 - 10s/epoch - 19ms/step
Epoch 20/40
500/500 - 10s - loss: 1.7109 - accuracy: 0.4622 - val_loss: 1.5540 - val_accuracy: 0.5065 - 10s/epoch - 20ms/step
Epoch 21/40
500/500 - 10s - loss: 1.7094 - accuracy: 0.4683 - val_loss: 1.5753 - val_accuracy: 0.5014 - 10s/epoch - 19ms/step
Epoch 22/40
500/500 - 10s - loss: 1.6858 - accuracy: 0.4696 - val_loss: 1.5582 - val_accuracy: 0.5026 - 10s/epoch - 20ms/step
Epoch 23/40
500/500 - 10s - loss: 1.6692 - accuracy: 0.4745 - val_loss: 1.6281 - val_accuracy: 0.4820 - 10s/epoch - 20ms/step
Epoch 24/40
500/500 - 10s - loss: 1.6772 - accuracy: 0.4714 - val_loss: 1.5393 - val_accuracy: 0.5147 - 10s/epoch - 20ms/step
Epoch 25/40
500/500 - 10s - loss: 1.6572 - accuracy: 0.4764 - val_loss: 1.5389 - val_accuracy: 0.5101 - 10s/epoch - 21ms/step
Epoch 26/40
500/500 - 10s - loss: 1.6422 - accuracy: 0.4841 - val_loss: 1.5401 - val_accuracy: 0.5128 - 10s/epoch - 20ms/step
Epoch 27/40
500/500 - 10s - loss: 1.6238 - accuracy: 0.4886 - val_loss: 1.6175 - val_accuracy: 0.4972 - 10s/epoch - 19ms/step
Epoch 28/40
500/500 - 10s - loss: 1.6153 - accuracy: 0.4889 - val_loss: 1.5045 - val_accuracy: 0.5233 - 10s/epoch - 19ms/step
Epoch 29/40
500/500 - 10s - loss: 1.5900 - accuracy: 0.4993 - val_loss: 1.5149 - val_accuracy: 0.5254 - 10s/epoch - 20ms/step
Epoch 30/40
500/500 - 10s - loss: 1.5811 - accuracy: 0.5064 - val_loss: 1.5418 - val_accuracy: 0.5141 - 10s/epoch - 19ms/step
Epoch 31/40
500/500 - 10s - loss: 1.5801 - accuracy: 0.5050 - val_loss: 1.5037 - val_accuracy: 0.5175 - 10s/epoch - 21ms/step
Epoch 32/40
500/500 - 10s - loss: 1.5739 - accuracy: 0.5073 - val_loss: 1.5198 - val_accuracy: 0.5203 - 10s/epoch - 20ms/step
Epoch 33/40
500/500 - 10s - loss: 1.5758 - accuracy: 0.5028 - val_loss: 1.5781 - val_accuracy: 0.5081 - 10s/epoch - 19ms/step
Epoch 34/40
500/500 - 10s - loss: 1.5787 - accuracy: 0.5007 - val_loss: 1.4648 - val_accuracy: 0.5351 - 10s/epoch - 19ms/step
Epoch 35/40
500/500 - 10s - loss: 1.5317 - accuracy: 0.5172 - val_loss: 1.4532 - val_accuracy: 0.5400 - 10s/epoch - 20ms/step
Epoch 36/40
500/500 - 10s - loss: 1.5581 - accuracy: 0.5079 - val_loss: 1.4553 - val_accuracy: 0.5352 - 10s/epoch - 20ms/step
Epoch 37/40
500/500 - 10s - loss: 1.5207 - accuracy: 0.5199 - val_loss: 1.5332 - val_accuracy: 0.5152 - 10s/epoch - 19ms/step
Epoch 38/40
500/500 - 10s - loss: 1.5186 - accuracy: 0.5255 - val_loss: 1.4689 - val_accuracy: 0.5317 - 10s/epoch - 19ms/step
Epoch 39/40
500/500 - 10s - loss: 1.5251 - accuracy: 0.5187 - val_loss: 1.5200 - val_accuracy: 0.5256 - 10s/epoch - 20ms/step
Epoch 40/40
500/500 - 10s - loss: 1.5154 - accuracy: 0.5217 - val_loss: 1.4429 - val_accuracy: 0.5464 - 10s/epoch - 20ms/step
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/60c1e53b7a8503d3361df99cfd3e44ff937348fa.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Train accuracy of the model: 52.16875076293945
Train loss of the model:  1.5154067277908325
Validation accuracy of the model:  0.5464000105857849
Validation loss of the model:  1.442899227142334
Test Loss: 1.442899227142334
Test Accuracy: 0.5464000105857849
</code></pre>
</div>
</div>
<div class="cell markdown" id="rbH71j0bS6ls">
<p>Data Augmentation works well for the models for this dataset however the test and validation accuracy without data augmentation is much higher</p>
</div>
<section id="best-model---baseline-model-3--dropout" class="cell markdown" id="7VPX6NPHlB1W">
<h3>BEST MODEL - Baseline model 3 + Dropout</h3>
</section>
<div class="cell code" id="g0qcj92aH4cu">
<div class="sourceCode" id="cb82"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>, input_shape<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)))</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb82-10"><a href="#cb82-10" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb82-11"><a href="#cb82-11" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(<span class="dv">128</span>, (<span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>))</span>
<span id="cb82-12"><a href="#cb82-12" aria-hidden="true" tabindex="-1"></a>model.add(MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb82-13"><a href="#cb82-13" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb82-14"><a href="#cb82-14" aria-hidden="true" tabindex="-1"></a>model.add(Flatten())</span>
<span id="cb82-15"><a href="#cb82-15" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_uniform&#39;</span>))</span>
<span id="cb82-16"><a href="#cb82-16" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))</span>
<span id="cb82-17"><a href="#cb82-17" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>))</span>
<span id="cb82-18"><a href="#cb82-18" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span> <span class="st">&#39;adam&#39;</span>, loss<span class="op">=</span><span class="st">&#39;categorical_crossentropy&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span></code></pre></div>
</div>
<div class="cell code" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="eqXkl90JNYbk" data-outputId="7032ffb2-4dd8-4671-8efc-225ea733f81e">
<div class="sourceCode" id="cb83"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>scores, histories <span class="op">=</span> <span class="bu">list</span>(), <span class="bu">list</span>()</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>model.summary()</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">40</span>, batch_size<span class="op">=</span><span class="dv">32</span>, validation_data<span class="op">=</span>(X_test, y_test), verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a><span class="co"># evaluate model</span></span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>_, acc <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a>scores.append(acc)</span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a>histories.append(history)</span>
<span id="cb83-9"><a href="#cb83-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-10"><a href="#cb83-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb83-11"><a href="#cb83-11" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb83-12"><a href="#cb83-12" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">&#39;Train Results&#39;</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb83-13"><a href="#cb83-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb83-14"><a href="#cb83-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb83-15"><a href="#cb83-15" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;b&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb83-16"><a href="#cb83-16" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_loss&#39;</span>], color<span class="op">=</span><span class="st">&#39;r&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb83-17"><a href="#cb83-17" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb83-18"><a href="#cb83-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-19"><a href="#cb83-19" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb83-20"><a href="#cb83-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Number of Epochs&quot;</span>)</span>
<span id="cb83-21"><a href="#cb83-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb83-22"><a href="#cb83-22" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb83-23"><a href="#cb83-23" aria-hidden="true" tabindex="-1"></a>plt.plot(history.history[<span class="st">&#39;val_accuracy&#39;</span>], color<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Validation Accuracy&#39;</span>)</span>
<span id="cb83-24"><a href="#cb83-24" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb83-25"><a href="#cb83-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb83-26"><a href="#cb83-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-27"><a href="#cb83-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Train accuracy of the model:&#39;</span>, (history.history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb83-28"><a href="#cb83-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Train loss of the model: &#39;</span>,history.history[<span class="st">&#39;loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb83-29"><a href="#cb83-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation accuracy of the model: &#39;</span>,history.history[<span class="st">&#39;val_accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb83-30"><a href="#cb83-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Validation loss of the model: &#39;</span>,history.history[<span class="st">&#39;val_loss&#39;</span>][<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb83-31"><a href="#cb83-31" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> model.evaluate(X_test,y_test,verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb83-32"><a href="#cb83-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Loss:&quot;</span>,score[<span class="dv">0</span>])</span>
<span id="cb83-33"><a href="#cb83-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Test Accuracy:&quot;</span>,score[<span class="dv">1</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential_9&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_48 (Conv2D)          (None, 32, 32, 32)        896       
                                                                 
 conv2d_49 (Conv2D)          (None, 32, 32, 32)        9248      
                                                                 
 max_pooling2d_24 (MaxPoolin  (None, 16, 16, 32)       0         
 g2D)                                                            
                                                                 
 dropout_24 (Dropout)        (None, 16, 16, 32)        0         
                                                                 
 conv2d_50 (Conv2D)          (None, 16, 16, 64)        18496     
                                                                 
 conv2d_51 (Conv2D)          (None, 16, 16, 64)        36928     
                                                                 
 max_pooling2d_25 (MaxPoolin  (None, 8, 8, 64)         0         
 g2D)                                                            
                                                                 
 dropout_25 (Dropout)        (None, 8, 8, 64)          0         
                                                                 
 conv2d_52 (Conv2D)          (None, 8, 8, 128)         73856     
                                                                 
 conv2d_53 (Conv2D)          (None, 8, 8, 128)         147584    
                                                                 
 max_pooling2d_26 (MaxPoolin  (None, 4, 4, 128)        0         
 g2D)                                                            
                                                                 
 dropout_26 (Dropout)        (None, 4, 4, 128)         0         
                                                                 
 flatten_9 (Flatten)         (None, 2048)              0         
                                                                 
 dense_18 (Dense)            (None, 128)               262272    
                                                                 
 dropout_27 (Dropout)        (None, 128)               0         
                                                                 
 dense_19 (Dense)            (None, 100)               12900     
                                                                 
=================================================================
Total params: 562,180
Trainable params: 562,180
Non-trainable params: 0
_________________________________________________________________
Epoch 1/40
1563/1563 [==============================] - 10s 6ms/step - loss: 2.4750 - accuracy: 0.2370 - val_loss: 2.1611 - val_accuracy: 0.3390
Epoch 2/40
1563/1563 [==============================] - 10s 6ms/step - loss: 2.0708 - accuracy: 0.3607 - val_loss: 1.8706 - val_accuracy: 0.4197
Epoch 3/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.8732 - accuracy: 0.4159 - val_loss: 1.8423 - val_accuracy: 0.4256
Epoch 4/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.7236 - accuracy: 0.4596 - val_loss: 1.6045 - val_accuracy: 0.4985
Epoch 5/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.6234 - accuracy: 0.4897 - val_loss: 1.5558 - val_accuracy: 0.5060
Epoch 6/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.5468 - accuracy: 0.5112 - val_loss: 1.5271 - val_accuracy: 0.5214
Epoch 7/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.4798 - accuracy: 0.5293 - val_loss: 1.4280 - val_accuracy: 0.5494
Epoch 8/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.4272 - accuracy: 0.5498 - val_loss: 1.4887 - val_accuracy: 0.5331
Epoch 9/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.3786 - accuracy: 0.5608 - val_loss: 1.4166 - val_accuracy: 0.5538
Epoch 10/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.3474 - accuracy: 0.5724 - val_loss: 1.4104 - val_accuracy: 0.5599
Epoch 11/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.3145 - accuracy: 0.5806 - val_loss: 1.4311 - val_accuracy: 0.5592
Epoch 12/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.2884 - accuracy: 0.5874 - val_loss: 1.4009 - val_accuracy: 0.5650
Epoch 13/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.2585 - accuracy: 0.5963 - val_loss: 1.3660 - val_accuracy: 0.5736
Epoch 14/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.2305 - accuracy: 0.6040 - val_loss: 1.3553 - val_accuracy: 0.5769
Epoch 15/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.2115 - accuracy: 0.6086 - val_loss: 1.3624 - val_accuracy: 0.5772
Epoch 16/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.1911 - accuracy: 0.6174 - val_loss: 1.4046 - val_accuracy: 0.5724
Epoch 17/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.1847 - accuracy: 0.6193 - val_loss: 1.3574 - val_accuracy: 0.5822
Epoch 18/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.1634 - accuracy: 0.6233 - val_loss: 1.3571 - val_accuracy: 0.5859
Epoch 19/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.1477 - accuracy: 0.6266 - val_loss: 1.3849 - val_accuracy: 0.5789
Epoch 20/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.1346 - accuracy: 0.6318 - val_loss: 1.4166 - val_accuracy: 0.5708
Epoch 21/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.1196 - accuracy: 0.6389 - val_loss: 1.3461 - val_accuracy: 0.5838
Epoch 22/40
1563/1563 [==============================] - 10s 7ms/step - loss: 1.1091 - accuracy: 0.6391 - val_loss: 1.3495 - val_accuracy: 0.5831
Epoch 23/40
1563/1563 [==============================] - 10s 7ms/step - loss: 1.1076 - accuracy: 0.6397 - val_loss: 1.3578 - val_accuracy: 0.5815
Epoch 24/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0936 - accuracy: 0.6475 - val_loss: 1.3898 - val_accuracy: 0.5832
Epoch 25/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0842 - accuracy: 0.6493 - val_loss: 1.3717 - val_accuracy: 0.5778
Epoch 26/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0766 - accuracy: 0.6533 - val_loss: 1.3813 - val_accuracy: 0.5835
Epoch 27/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0708 - accuracy: 0.6540 - val_loss: 1.3433 - val_accuracy: 0.5920
Epoch 28/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0573 - accuracy: 0.6540 - val_loss: 1.3728 - val_accuracy: 0.5767
Epoch 29/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0620 - accuracy: 0.6540 - val_loss: 1.3626 - val_accuracy: 0.5874
Epoch 30/40
1563/1563 [==============================] - 10s 7ms/step - loss: 1.0439 - accuracy: 0.6631 - val_loss: 1.3670 - val_accuracy: 0.5901
Epoch 31/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0400 - accuracy: 0.6637 - val_loss: 1.3779 - val_accuracy: 0.5910
Epoch 32/40
1563/1563 [==============================] - 10s 7ms/step - loss: 1.0398 - accuracy: 0.6640 - val_loss: 1.3640 - val_accuracy: 0.5898
Epoch 33/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0145 - accuracy: 0.6709 - val_loss: 1.3622 - val_accuracy: 0.5923
Epoch 34/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0120 - accuracy: 0.6703 - val_loss: 1.3502 - val_accuracy: 0.5966
Epoch 35/40
1563/1563 [==============================] - 10s 6ms/step - loss: 1.0163 - accuracy: 0.6684 - val_loss: 1.3716 - val_accuracy: 0.5927
Epoch 36/40
1563/1563 [==============================] - 10s 7ms/step - loss: 1.0008 - accuracy: 0.6760 - val_loss: 1.4041 - val_accuracy: 0.5872
Epoch 37/40
1563/1563 [==============================] - 10s 7ms/step - loss: 1.0029 - accuracy: 0.6742 - val_loss: 1.3506 - val_accuracy: 0.5954
Epoch 38/40
1563/1563 [==============================] - 11s 7ms/step - loss: 0.9972 - accuracy: 0.6767 - val_loss: 1.4183 - val_accuracy: 0.5840
Epoch 39/40
1563/1563 [==============================] - 10s 7ms/step - loss: 0.9935 - accuracy: 0.6767 - val_loss: 1.4310 - val_accuracy: 0.5814
Epoch 40/40
1563/1563 [==============================] - 10s 6ms/step - loss: 0.9819 - accuracy: 0.6804 - val_loss: 1.3938 - val_accuracy: 0.5877
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/a290892607ccf7866b96067bbf2130ae9107bd36.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>
Train accuracy of the model: 68.0400013923645
Train loss of the model:  0.9819034337997437
Validation accuracy of the model:  0.5877000093460083
Validation loss of the model:  1.3938287496566772
Test Loss: 1.3938287496566772
Test Accuracy: 0.5877000093460083
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>The model has a decent test accuracy and train accuracy and is not as overfitted as baseline model 3</p>
</div>
<section id="results" class="cell markdown" id="bWIsMV_wNofW">
<h2>RESULTS</h2>
</section>
<div class="cell code" data-colab="{&quot;height&quot;:1000,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="_puel_Y_NYeQ" data-outputId="89af945e-90c2-47f3-8f4a-642810fab47f">
<div class="sourceCode" id="cb86"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># confusion matrix</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_test)</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>y_pred_classes <span class="op">=</span> np.argmax(y_pred, axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> np.argmax(y_test, axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>confusion_mtx <span class="op">=</span> confusion_matrix(y_true, y_pred_classes) </span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>f,ax <span class="op">=</span> plt.subplots(figsize <span class="op">=</span> (<span class="dv">20</span>,<span class="dv">20</span>))</span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a>sns.heatmap(confusion_mtx, annot<span class="op">=</span><span class="va">True</span>, linewidths<span class="op">=</span><span class="fl">0.1</span>, cmap <span class="op">=</span> <span class="st">&quot;gist_yarg_r&quot;</span>, linecolor<span class="op">=</span><span class="st">&quot;black&quot;</span>, fmt<span class="op">=</span><span class="st">&#39;.0f&#39;</span>, ax<span class="op">=</span>ax)</span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Predicted Label&quot;</span>)</span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&quot;True Label&quot;</span>)</span>
<span id="cb86-12"><a href="#cb86-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Confusion Matrix&quot;</span>)</span>
<span id="cb86-13"><a href="#cb86-13" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>313/313 [==============================] - 1s 3ms/step
</code></pre>
</div>
<div class="output display_data">
<p><img src="vertopal_358e6f7a532443a091b337fff0b76682/1ceef3ea1a6e27e443103896272f1c507d24f627.png" /></p>
</div>
</div>
<div class="cell code" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" id="roGeBDauNsQu" data-outputId="8f1e6b40-193a-4fcc-c150-48228bb93cce">
<div class="sourceCode" id="cb88"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(confusion_mtx)):</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Class:&quot;</span>,<span class="bu">str</span>(i))</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Number of Wrong Prediction:&quot;</span>, <span class="bu">str</span>(<span class="bu">sum</span>(confusion_mtx[i])<span class="op">-</span>confusion_mtx[i][i]), <span class="st">&quot;out of 1000&quot;</span>)</span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Percentage of True Prediction: </span><span class="sc">{:.2f}</span><span class="st">%&quot;</span>.<span class="bu">format</span>(confusion_mtx[i][i] <span class="op">/</span> <span class="dv">10</span>))</span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;***********************************************************&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Class: 0
Number of Wrong Prediction: 260 out of 1000
Percentage of True Prediction: 24.00%
***********************************************************
Class: 1
Number of Wrong Prediction: 229 out of 1000
Percentage of True Prediction: 27.10%
***********************************************************
Class: 2
Number of Wrong Prediction: 101 out of 1000
Percentage of True Prediction: 39.90%
***********************************************************
Class: 3
Number of Wrong Prediction: 167 out of 1000
Percentage of True Prediction: 33.30%
***********************************************************
Class: 4
Number of Wrong Prediction: 181 out of 1000
Percentage of True Prediction: 31.90%
***********************************************************
Class: 5
Number of Wrong Prediction: 243 out of 1000
Percentage of True Prediction: 25.70%
***********************************************************
Class: 6
Number of Wrong Prediction: 158 out of 1000
Percentage of True Prediction: 34.20%
***********************************************************
Class: 7
Number of Wrong Prediction: 248 out of 1000
Percentage of True Prediction: 25.20%
***********************************************************
Class: 8
Number of Wrong Prediction: 252 out of 1000
Percentage of True Prediction: 24.80%
***********************************************************
Class: 9
Number of Wrong Prediction: 160 out of 1000
Percentage of True Prediction: 34.00%
***********************************************************
Class: 10
Number of Wrong Prediction: 101 out of 1000
Percentage of True Prediction: 39.90%
***********************************************************
Class: 11
Number of Wrong Prediction: 284 out of 1000
Percentage of True Prediction: 21.60%
***********************************************************
Class: 12
Number of Wrong Prediction: 285 out of 1000
Percentage of True Prediction: 21.50%
***********************************************************
Class: 13
Number of Wrong Prediction: 265 out of 1000
Percentage of True Prediction: 23.50%
***********************************************************
Class: 14
Number of Wrong Prediction: 180 out of 1000
Percentage of True Prediction: 32.00%
***********************************************************
Class: 15
Number of Wrong Prediction: 313 out of 1000
Percentage of True Prediction: 18.70%
***********************************************************
Class: 16
Number of Wrong Prediction: 266 out of 1000
Percentage of True Prediction: 23.40%
***********************************************************
Class: 17
Number of Wrong Prediction: 71 out of 1000
Percentage of True Prediction: 42.90%
***********************************************************
Class: 18
Number of Wrong Prediction: 194 out of 1000
Percentage of True Prediction: 30.60%
***********************************************************
Class: 19
Number of Wrong Prediction: 165 out of 1000
Percentage of True Prediction: 33.50%
***********************************************************
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>The performance for this model is also not bad</p>
</div>
</body>
</html>
